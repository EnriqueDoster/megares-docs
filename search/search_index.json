{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MEGARes The MEGARes database contains sequence data for approximately 8,000 hand-curated antimicrobial resistance genes accompanied by an annotation structure that is optimized for use with high throughput sequencing. The acyclical annotation graph of MEGARes allows for accurate, count-based, hierarchical statistical analysis of resistance at the population level, much like microbiome analysis, and is also designed to be used as a training database for the creation of statistical classifiers (Figure 1). Figure 1 A.) This annotation graph contains no cycles (is a tree), as nodes 1 and 2 do not share children and are therefore independent. B.) In contrast, node 3 and node 4 share node 5 as a child, which creates a cycle in the annotation graph. When should I use MEGARes? For the population-level profiling or population comparison of antimicrobial resistance (count-based analyses, similar to microbiome analysis). MEGARes can also be used for the construction of sequence classifiers, e.g. naive Bayes, hidden Markov models. For users who wish to predict the protein function and functional mutations in their sequencing data, we recommend using a database suited for functional genomics, such as the Comprehensive Antibiotic Resistance Database (CARD). What distinguishes MEGARes from other databases? MEGARes has been designed for use in the computational analysis of large-scale sequencing data (on the order of terabytes) in a way that is fast and statistically accurate for count-based data and the construction of sequence classifiers. The latest update in MEGARes 2.0 (https://megares.meglab.org) incorporates previously published resistance sequences for antimicrobial drugs, while also expanding to include published sequences for metal and biocide resistance determinants. Sequences are annotated in a biologically meaningful way that preserves within-group nucleotide similarity. The annotation graph contains no cycles. Therefore, it contains no statistical dependencies and is accurate for the count-based analyses commonly performed in population-level profiling (Figure 1). The annotation graph contains only three hierarchical levels, which maximizes the number of representative sequences for each annotation node. This is designed to work well for the construction of statistical classifiers. The annotation levels are: Type: the type of antimicrobial compound, e.g. drugs, biocides, multi-compound Class: the major antimicrobial chemical class, e.g. betalactams, aminoglycosides Mechanism: the biological mechanism of resistance, e.g. penicillin binding protein Group: the gene- or operon-level group for that sequence, e.g. SHV betalactamase, MCR-1 All sequence metadata has been formatted to work well with the majority of bioinformatics software. Sequence headers contain no whitespace or non-compliant symbols. All sequences and annotations have been hand-curated using a multi-factorial approach. See the manuscript for more details. Citation for MEGARes 2.0 and AMR++ 2.0: Doster, E., Lakin, S. M., Dean, C. J., Wolfe, C., Young, J. G., Boucher, C., Belk K. E., Noyes N. R., Morley P. S. (2019) MEGARes 2.0: a database for classification of antimicrobial drug, biocide and metal resistance determinants in metagenomic sequence data. Nucleic Acids Res. doi:10.1093/nar/gkz1010. Click to Download Citation in different formats Citation for MEGARes and AmrPlusPlus: Lakin, S.M., Dean, C., Noyes, N.R., Dettenwanger, A., Spencer Ross, A., Doster, E., Rovira, P., Abdo, Z., Jones, K.L., Ruiz, J., Belk, K.E., Morley, P.S., Boucher, C. (2016) MEGARes: an antimicrobial database for high throughput sequencing. Nucleic Acids Res., 45. DOI: 10.1093/nar/gkw1009 Click to Download Citation","title":"Home"},{"location":"#welcome-to-megares","text":"The MEGARes database contains sequence data for approximately 8,000 hand-curated antimicrobial resistance genes accompanied by an annotation structure that is optimized for use with high throughput sequencing. The acyclical annotation graph of MEGARes allows for accurate, count-based, hierarchical statistical analysis of resistance at the population level, much like microbiome analysis, and is also designed to be used as a training database for the creation of statistical classifiers (Figure 1). Figure 1 A.) This annotation graph contains no cycles (is a tree), as nodes 1 and 2 do not share children and are therefore independent. B.) In contrast, node 3 and node 4 share node 5 as a child, which creates a cycle in the annotation graph.","title":"Welcome to MEGARes"},{"location":"#when-should-i-use-megares","text":"For the population-level profiling or population comparison of antimicrobial resistance (count-based analyses, similar to microbiome analysis). MEGARes can also be used for the construction of sequence classifiers, e.g. naive Bayes, hidden Markov models. For users who wish to predict the protein function and functional mutations in their sequencing data, we recommend using a database suited for functional genomics, such as the Comprehensive Antibiotic Resistance Database (CARD).","title":"When should I use MEGARes?"},{"location":"#what-distinguishes-megares-from-other-databases","text":"MEGARes has been designed for use in the computational analysis of large-scale sequencing data (on the order of terabytes) in a way that is fast and statistically accurate for count-based data and the construction of sequence classifiers. The latest update in MEGARes 2.0 (https://megares.meglab.org) incorporates previously published resistance sequences for antimicrobial drugs, while also expanding to include published sequences for metal and biocide resistance determinants. Sequences are annotated in a biologically meaningful way that preserves within-group nucleotide similarity. The annotation graph contains no cycles. Therefore, it contains no statistical dependencies and is accurate for the count-based analyses commonly performed in population-level profiling (Figure 1). The annotation graph contains only three hierarchical levels, which maximizes the number of representative sequences for each annotation node. This is designed to work well for the construction of statistical classifiers. The annotation levels are: Type: the type of antimicrobial compound, e.g. drugs, biocides, multi-compound Class: the major antimicrobial chemical class, e.g. betalactams, aminoglycosides Mechanism: the biological mechanism of resistance, e.g. penicillin binding protein Group: the gene- or operon-level group for that sequence, e.g. SHV betalactamase, MCR-1 All sequence metadata has been formatted to work well with the majority of bioinformatics software. Sequence headers contain no whitespace or non-compliant symbols. All sequences and annotations have been hand-curated using a multi-factorial approach. See the manuscript for more details.","title":"What distinguishes MEGARes from other databases?"},{"location":"#citation-for-megares-20-and-amr-20","text":"Doster, E., Lakin, S. M., Dean, C. J., Wolfe, C., Young, J. G., Boucher, C., Belk K. E., Noyes N. R., Morley P. S. (2019) MEGARes 2.0: a database for classification of antimicrobial drug, biocide and metal resistance determinants in metagenomic sequence data. Nucleic Acids Res. doi:10.1093/nar/gkz1010. Click to Download Citation in different formats","title":"Citation for MEGARes 2.0 and AMR++ 2.0:"},{"location":"#citation-for-megares-and-amrplusplus","text":"Lakin, S.M., Dean, C., Noyes, N.R., Dettenwanger, A., Spencer Ross, A., Doster, E., Rovira, P., Abdo, Z., Jones, K.L., Ruiz, J., Belk, K.E., Morley, P.S., Boucher, C. (2016) MEGARes: an antimicrobial database for high throughput sequencing. Nucleic Acids Res., 45. DOI: 10.1093/nar/gkw1009 Click to Download Citation","title":"Citation for MEGARes and AmrPlusPlus:"},{"location":"changelog/","text":"Changelog 2016-12-01 Headers and annotations updated to identify the sequences that require SNP confirmation for functional resistance 2016-10-12 Updated database online and zip file 2016-10-08 Updated descriptions and references 2016-09-29 Added search functionality to the website. 2016-09-26 Updated descriptions and references","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#2016-12-01","text":"Headers and annotations updated to identify the sequences that require SNP confirmation for functional resistance","title":"2016-12-01"},{"location":"changelog/#2016-10-12","text":"Updated database online and zip file","title":"2016-10-12"},{"location":"changelog/#2016-10-08","text":"Updated descriptions and references","title":"2016-10-08"},{"location":"changelog/#2016-09-29","text":"Added search functionality to the website.","title":"2016-09-29"},{"location":"changelog/#2016-09-26","text":"Updated descriptions and references","title":"2016-09-26"},{"location":"download/","text":"Downloads 2.0.0 (2019-10-14) All Sequences (.fasta) Annotations (.csv) Annotations with notes (.csv) Mapping (.csv) Drug resistance sequences (.fasta) Drug resistance Annotations (.csv) All Files (.zip) 1.0.1 (2016-12-01) All Sequences (.fasta) Annotations (.csv) Mapping (.tsv) All Files (.zip) 1.0.0 (2016-10-25) All Sequences (.fasta) Annotations (.csv) Mapping (.tsv) All Files (.zip)","title":"Downloads"},{"location":"download/#downloads","text":"","title":"Downloads"},{"location":"download/#200-2019-10-14","text":"All Sequences (.fasta) Annotations (.csv) Annotations with notes (.csv) Mapping (.csv) Drug resistance sequences (.fasta) Drug resistance Annotations (.csv) All Files (.zip)","title":"2.0.0 (2019-10-14)"},{"location":"download/#101-2016-12-01","text":"All Sequences (.fasta) Annotations (.csv) Mapping (.tsv) All Files (.zip)","title":"1.0.1 (2016-12-01)"},{"location":"download/#100-2016-10-25","text":"All Sequences (.fasta) Annotations (.csv) Mapping (.tsv) All Files (.zip)","title":"1.0.0 (2016-10-25)"},{"location":"armplusplus/latest/FAQs/","text":"Troubleshooting and frequently asked questions (FAQs) Many errors that may be encountered may ultimately be the result of user error. If you encounter an error message any time that this pipeline is used, carefully check the command you used for any spelling errors. Additionally, many of these error messages give some detail as too where the code is wrong. Here are a few common errors and our suggestions for basic troubleshooting. Are you using the correct \"profile\" to run AmrPlusPlus? We provide many examples of profile configurations and choosing the correct one depends on your computing environment. If you have singularity installed on your server, we recommend using the \"singularity\" profile to avoid the installation of any additional tools. If you already have the tools installed on your server, the best option is to configure the local.config file to point to the absolute PATH to each too. Are the right user permissions are granted to the file/directory/server in which you are going to run the pipeline? In servers with multiple users, there are often cases in which certain directories give some users more editing privileges than others. Start by navigating to the directory in which you will be working. Next, type ls -lha or ls -l . This produces a list of all files in that directory and info on what permissions the user has using the -rwxrwxrwx scheme; r = read permissions, w = writing permissions, and x = execute permissions). Permission errors could be due to the directories chosen for the pipeline output or individual bioinformatic tools installed by other users, for example. Review this tutorial for more information regarding file permissions: https://www.guru99.com/file-permissions.html","title":"FAQ"},{"location":"armplusplus/latest/FAQs/#troubleshooting-and-frequently-asked-questions-faqs","text":"Many errors that may be encountered may ultimately be the result of user error. If you encounter an error message any time that this pipeline is used, carefully check the command you used for any spelling errors. Additionally, many of these error messages give some detail as too where the code is wrong. Here are a few common errors and our suggestions for basic troubleshooting.","title":"Troubleshooting and frequently asked questions (FAQs)"},{"location":"armplusplus/latest/FAQs/#are-you-using-the-correct-profile-to-run-amrplusplus","text":"We provide many examples of profile configurations and choosing the correct one depends on your computing environment. If you have singularity installed on your server, we recommend using the \"singularity\" profile to avoid the installation of any additional tools. If you already have the tools installed on your server, the best option is to configure the local.config file to point to the absolute PATH to each too.","title":"Are you using the correct \"profile\" to run AmrPlusPlus?"},{"location":"armplusplus/latest/FAQs/#are-the-right-user-permissions-are-granted-to-the-filedirectoryserver-in-which-you-are-going-to-run-the-pipeline","text":"In servers with multiple users, there are often cases in which certain directories give some users more editing privileges than others. Start by navigating to the directory in which you will be working. Next, type ls -lha or ls -l . This produces a list of all files in that directory and info on what permissions the user has using the -rwxrwxrwx scheme; r = read permissions, w = writing permissions, and x = execute permissions). Permission errors could be due to the directories chosen for the pipeline output or individual bioinformatic tools installed by other users, for example. Review this tutorial for more information regarding file permissions: https://www.guru99.com/file-permissions.html","title":"Are the right user permissions are granted to the file/directory/server in which you are going to run the pipeline?"},{"location":"armplusplus/latest/accessing_AMR/","text":"Accessing AMR++ This section will help you get access to all the bioinformatic tools required for metagenomic analysis with AMR++. Amazon Web Services In order to facilitate evaluation of the MEGARes 2.0 database and the functionality of AMR++ 2.0 pipeline, we have provided free access to an Amazon Machine Image (AMI) with example files for analysis. AMR++ 2.0 is pre-installed and fully integrated with all necessary bioinformatic tools and dependencies within an AMI named \"Microbial_Ecology_Group_AMR_AMI\", allowing users to easily employ the AMR++ v2.0 pipeline within the Amazon Web Services (AWS) ecosystem. Please follow the instructions on amazon web services for details on creating your own EC2 instance ( https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html ). With this approach, users pay for the cost of a suitable AWS EC2 instance without the challenge of accessing large computing clusters and individually installing each piece of software necessary to run the pipeline (including all dependencies). Integration within AWS also allows users to scale the computing resources to fit the needs of any project size. Singularity container Singularity containers allow the packaging of multiple bioinformatic tools. While singularity is a popular tool and likely to be supported by many computing clusters, please contact your system administrator for help with installing singularity. Installation on a local computer is also an option and can be performed by following these instructions: https://sylabs.io/guides/3.0/user-guide/installation.html We provide AMR++ with a singularity container that is automatically accessed when running the AMR++ pipeline by using the flag, \"-profile singularity\". Additionally, the singularity container is supported on singularity-hub.org and can be used locally for custom analysis (https://singularity-hub.org/collections/3418) . # Choose your preference to pull the container from Singularity Hub (once) $ singularity pull shub://meglab-metagenomics/amrplusplus_v2 # Then interact with it (enter \"exit\" to leave the singularity container): $ singularity shell amrplusplus_v2.sif","title":"Accessing AMR Plus Plus v2.0"},{"location":"armplusplus/latest/accessing_AMR/#accessing-amr","text":"This section will help you get access to all the bioinformatic tools required for metagenomic analysis with AMR++.","title":"Accessing AMR++"},{"location":"armplusplus/latest/accessing_AMR/#amazon-web-services","text":"In order to facilitate evaluation of the MEGARes 2.0 database and the functionality of AMR++ 2.0 pipeline, we have provided free access to an Amazon Machine Image (AMI) with example files for analysis. AMR++ 2.0 is pre-installed and fully integrated with all necessary bioinformatic tools and dependencies within an AMI named \"Microbial_Ecology_Group_AMR_AMI\", allowing users to easily employ the AMR++ v2.0 pipeline within the Amazon Web Services (AWS) ecosystem. Please follow the instructions on amazon web services for details on creating your own EC2 instance ( https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html ). With this approach, users pay for the cost of a suitable AWS EC2 instance without the challenge of accessing large computing clusters and individually installing each piece of software necessary to run the pipeline (including all dependencies). Integration within AWS also allows users to scale the computing resources to fit the needs of any project size.","title":"Amazon Web Services"},{"location":"armplusplus/latest/accessing_AMR/#singularity-container","text":"Singularity containers allow the packaging of multiple bioinformatic tools. While singularity is a popular tool and likely to be supported by many computing clusters, please contact your system administrator for help with installing singularity. Installation on a local computer is also an option and can be performed by following these instructions: https://sylabs.io/guides/3.0/user-guide/installation.html We provide AMR++ with a singularity container that is automatically accessed when running the AMR++ pipeline by using the flag, \"-profile singularity\". Additionally, the singularity container is supported on singularity-hub.org and can be used locally for custom analysis (https://singularity-hub.org/collections/3418) . # Choose your preference to pull the container from Singularity Hub (once) $ singularity pull shub://meglab-metagenomics/amrplusplus_v2 # Then interact with it (enter \"exit\" to leave the singularity container): $ singularity shell amrplusplus_v2.sif","title":"Singularity container"},{"location":"armplusplus/latest/citing/","text":"Citation for MEGARes 2.0 and AMR++ 2.0: Doster, E., Lakin, S. M., Dean, C. J., Wolfe, C., Young, J. G., Boucher, C., Belk K. E., Noyes N. R., Morley P. S. (2019) MEGARes 2.0: a database for classification of antimicrobial drug, biocide and metal resistance determinants in metagenomic sequence data. Nucleic Acids Res. doi:10.1093/nar/gkz1010. Click to Download Citation in different formats","title":"Citing AMR++"},{"location":"armplusplus/latest/citing/#citation-for-megares-20-and-amr-20","text":"Doster, E., Lakin, S. M., Dean, C. J., Wolfe, C., Young, J. G., Boucher, C., Belk K. E., Noyes N. R., Morley P. S. (2019) MEGARes 2.0: a database for classification of antimicrobial drug, biocide and metal resistance determinants in metagenomic sequence data. Nucleic Acids Res. doi:10.1093/nar/gkz1010. Click to Download Citation in different formats","title":"Citation for MEGARes 2.0 and AMR++ 2.0:"},{"location":"armplusplus/latest/configuration/","text":"The pipeline source code comes with a configuration file that can be used to set environment variables or default command-line options. Setting these variables before hand may be useful in situations when you do not want to specify a long list of options from the command line. This configuration file can be found in the root source code directory and is called nextflow.config . You can modify this file, save the changes, and run the pipeline directly. Customize Environment Variables using profiles The nextflow.config contains a section that allows the use of environment \"profiles\" when running AmrPlusPlus. Further information for each profile can be found within the /config directory. In brief, profiles allow control over how the pipeline is run on different computing clusters. We recommend the \"singularity\" profile which employs a Singularity container with all the required bioinformatic tools. profiles { local { includeConfig \"config/local.config\" } local_angus { includeConfig \"config/local_angus.config\" } local_MSI { includeConfig \"config/local_MSI.config\" } slurm { process.executor = 'slurm' includeConfig \"config/slurm.config\" process.container = 'shub://meglab-metagenomics/amrplusplus_v2' } singularity { includeConfig \"config/singularity.config\" process.container = 'shub://meglab-metagenomics/amrplusplus_v2' } } Customize Command-line Options The params section allows you to set the different commmand-line options that can be used within the pipeline. Here, you can specify input/output options, trimming options, and algorithm options. If you intend to run multiple samples in parallel, you must specify a glob pattern for your sequence data as shown for the reads parameter. For more information on globs, please see this related article . By default, the pipeline uses the default minikraken database (~4GB) to classify and assign taxonomic labels to your sequences. As Kraken loads this database into memory, this mini database is particularly useful for people who do not have access to large memory servers. We provide a script to easily download the minikraken database. sh download_minikraken.sh If you would like to use a custom database or the standard Kraken database (~160GB), you will need to build it yourself and modify the kraken_db environment variable in the nextflow.config file to point to its location on your machine. params { /* Location of forward and reverse read pairs */ reads = \"data/raw/*_{1,2}.fastq.gz\" /* Location of adapter sequences */ adapters = \"data/adapters/nextera.fa\" /* Location of tab delimited adapter sequences */ fqc_adapters = \"data/adapters/nextera.tab\" /* Location of host genome index files */ host_index = \"\" /* Location of host genome */ host = \"data/host/chr21.fasta.gz\" /* Kraken database location, default is \"none\" */ kraken_db = \"minikraken2_v2_8GB_201904_UPDATE\" /* Location of amr index files */ amr_index = \"\" /* Location of antimicrobial resistance ( MEGARes ) database */ amr = \"data/amr/megares_database_v1.02.fasta\" /* Location of amr annotation file */ annotation = \"data/amr/megares_annotations_v1.02.csv\" /* Location of SNP metadata */ snp_annotation = \"data/amr/snp_location_metadata.csv\" /* Location of SNP confirmation script */ snp_confirmation = \"bin/snp_confirmation.py\" /* Output directory */ output = \"test_results\" /* Number of threads */ threads = 10 smem_threads = 12 /* Trimmomatic trimming parameters */ leading = 10 trailing = 3 slidingwindow = \"4:15\" minlen = 36 /* Resistome threshold */ threshold = 80 /* Starting rarefaction level */ min = 5 /* Ending rarefaction level */ max = 100 /* Number of levels to skip */ skip = 5 /* Number of iterations to sample at */ samples = 1 /* Display help message */ help = false }","title":"Configuration"},{"location":"armplusplus/latest/configuration/#customize-environment-variables-using-profiles","text":"The nextflow.config contains a section that allows the use of environment \"profiles\" when running AmrPlusPlus. Further information for each profile can be found within the /config directory. In brief, profiles allow control over how the pipeline is run on different computing clusters. We recommend the \"singularity\" profile which employs a Singularity container with all the required bioinformatic tools. profiles { local { includeConfig \"config/local.config\" } local_angus { includeConfig \"config/local_angus.config\" } local_MSI { includeConfig \"config/local_MSI.config\" } slurm { process.executor = 'slurm' includeConfig \"config/slurm.config\" process.container = 'shub://meglab-metagenomics/amrplusplus_v2' } singularity { includeConfig \"config/singularity.config\" process.container = 'shub://meglab-metagenomics/amrplusplus_v2' } }","title":"Customize Environment Variables using profiles"},{"location":"armplusplus/latest/configuration/#customize-command-line-options","text":"The params section allows you to set the different commmand-line options that can be used within the pipeline. Here, you can specify input/output options, trimming options, and algorithm options. If you intend to run multiple samples in parallel, you must specify a glob pattern for your sequence data as shown for the reads parameter. For more information on globs, please see this related article . By default, the pipeline uses the default minikraken database (~4GB) to classify and assign taxonomic labels to your sequences. As Kraken loads this database into memory, this mini database is particularly useful for people who do not have access to large memory servers. We provide a script to easily download the minikraken database. sh download_minikraken.sh If you would like to use a custom database or the standard Kraken database (~160GB), you will need to build it yourself and modify the kraken_db environment variable in the nextflow.config file to point to its location on your machine. params { /* Location of forward and reverse read pairs */ reads = \"data/raw/*_{1,2}.fastq.gz\" /* Location of adapter sequences */ adapters = \"data/adapters/nextera.fa\" /* Location of tab delimited adapter sequences */ fqc_adapters = \"data/adapters/nextera.tab\" /* Location of host genome index files */ host_index = \"\" /* Location of host genome */ host = \"data/host/chr21.fasta.gz\" /* Kraken database location, default is \"none\" */ kraken_db = \"minikraken2_v2_8GB_201904_UPDATE\" /* Location of amr index files */ amr_index = \"\" /* Location of antimicrobial resistance ( MEGARes ) database */ amr = \"data/amr/megares_database_v1.02.fasta\" /* Location of amr annotation file */ annotation = \"data/amr/megares_annotations_v1.02.csv\" /* Location of SNP metadata */ snp_annotation = \"data/amr/snp_location_metadata.csv\" /* Location of SNP confirmation script */ snp_confirmation = \"bin/snp_confirmation.py\" /* Output directory */ output = \"test_results\" /* Number of threads */ threads = 10 smem_threads = 12 /* Trimmomatic trimming parameters */ leading = 10 trailing = 3 slidingwindow = \"4:15\" minlen = 36 /* Resistome threshold */ threshold = 80 /* Starting rarefaction level */ min = 5 /* Ending rarefaction level */ max = 100 /* Number of levels to skip */ skip = 5 /* Number of iterations to sample at */ samples = 1 /* Display help message */ help = false }","title":"Customize Command-line Options"},{"location":"armplusplus/latest/contact/","text":"Contact Questions, bugs, or feature requests should be directed to meglab.metagenomics@gmail.com","title":"Contact"},{"location":"armplusplus/latest/contact/#contact","text":"Questions, bugs, or feature requests should be directed to meglab.metagenomics@gmail.com","title":"Contact"},{"location":"armplusplus/latest/dependencies/","text":"Dependencies AmrPlusPlus uses a variety of open-source tools. The tools used, descriptions, and version specifics are provided below. Bedtools Description: Bedtools is a suite of tools that can be used to compute and extract useful information from BAM, BED, and BCF files. Version: 2.28.0 DOI: https://doi.org/10.1093/bioinformatics/btq033 BWA Description: BWA is a short and long read sequence aligner for aligning raw sequence data to a reference genome. Version: 0.7.17 DOI: https://doi.org/10.1093/bioinformatics/btp324 Kraken2 Description: Kraken is a fast taxonomic sequence classifier that assigns taxonomy labels to short-reads. Version: 2.0.8 DOI: https://doi.org/10.1186/gb-2014-15-3-r46 RarefactionAnalyzer Description: RarefactionAnalyzer is a tool that can be used for performing rarefaction analysis. Version: 0.0.0 DOI: https://doi.org/10.1093/nar/gkw1009 ResistomeAnalyzer Description: ResistomeAnalyzer is a tool for analyzing the resistome of large metagenomic datasets. Version: 0.0.0 DOI: https://doi.org/10.1093/nar/gkw1009 Samtools Description: Samtools is a program for manipulating and extracting useful information from alignment files in SAM or BAM format. Version: 1.9 DOI: https://doi.org/10.1093/bioinformatics/btp352 SNPFinder Description: SNPFinder is a haplotype variant caller that can be used for metagenomics datasets. Version: 0.0.0 DOI: https://doi.org/10.1093/nar/gkw1009 Trimmomatic Description: Trimmomatic is a tool for removing low quality base pairs (bps) and adapter sequences from raw sequence data. Version: 0.39 DOI: https://doi.org/10.1093/bioinformatics/btu170 Freebayes Description: Trimmomatic is a tool for removing low quality base pairs (bps) and adapter sequences from raw sequence data. Version: 1.3.1 https://arxiv.org/abs/1207.3907v2 Resistance Gene Identifier Description: Trimmomatic is a tool for removing low quality base pairs (bps) and adapter sequences from raw sequence data. Version: 0.39 https://card.mcmaster.ca/analyze/rgi","title":"Dependencies"},{"location":"armplusplus/latest/dependencies/#dependencies","text":"AmrPlusPlus uses a variety of open-source tools. The tools used, descriptions, and version specifics are provided below.","title":"Dependencies"},{"location":"armplusplus/latest/dependencies/#bedtools","text":"Description: Bedtools is a suite of tools that can be used to compute and extract useful information from BAM, BED, and BCF files. Version: 2.28.0 DOI: https://doi.org/10.1093/bioinformatics/btq033","title":"Bedtools"},{"location":"armplusplus/latest/dependencies/#bwa","text":"Description: BWA is a short and long read sequence aligner for aligning raw sequence data to a reference genome. Version: 0.7.17 DOI: https://doi.org/10.1093/bioinformatics/btp324","title":"BWA"},{"location":"armplusplus/latest/dependencies/#kraken2","text":"Description: Kraken is a fast taxonomic sequence classifier that assigns taxonomy labels to short-reads. Version: 2.0.8 DOI: https://doi.org/10.1186/gb-2014-15-3-r46","title":"Kraken2"},{"location":"armplusplus/latest/dependencies/#rarefactionanalyzer","text":"Description: RarefactionAnalyzer is a tool that can be used for performing rarefaction analysis. Version: 0.0.0 DOI: https://doi.org/10.1093/nar/gkw1009","title":"RarefactionAnalyzer"},{"location":"armplusplus/latest/dependencies/#resistomeanalyzer","text":"Description: ResistomeAnalyzer is a tool for analyzing the resistome of large metagenomic datasets. Version: 0.0.0 DOI: https://doi.org/10.1093/nar/gkw1009","title":"ResistomeAnalyzer"},{"location":"armplusplus/latest/dependencies/#samtools","text":"Description: Samtools is a program for manipulating and extracting useful information from alignment files in SAM or BAM format. Version: 1.9 DOI: https://doi.org/10.1093/bioinformatics/btp352","title":"Samtools"},{"location":"armplusplus/latest/dependencies/#snpfinder","text":"Description: SNPFinder is a haplotype variant caller that can be used for metagenomics datasets. Version: 0.0.0 DOI: https://doi.org/10.1093/nar/gkw1009","title":"SNPFinder"},{"location":"armplusplus/latest/dependencies/#trimmomatic","text":"Description: Trimmomatic is a tool for removing low quality base pairs (bps) and adapter sequences from raw sequence data. Version: 0.39 DOI: https://doi.org/10.1093/bioinformatics/btu170","title":"Trimmomatic"},{"location":"armplusplus/latest/dependencies/#freebayes","text":"Description: Trimmomatic is a tool for removing low quality base pairs (bps) and adapter sequences from raw sequence data. Version: 1.3.1 https://arxiv.org/abs/1207.3907v2","title":"Freebayes"},{"location":"armplusplus/latest/dependencies/#resistance-gene-identifier","text":"Description: Trimmomatic is a tool for removing low quality base pairs (bps) and adapter sequences from raw sequence data. Version: 0.39 https://card.mcmaster.ca/analyze/rgi","title":"Resistance Gene Identifier"},{"location":"armplusplus/latest/installation/","text":"Installation This section will help you get started with running the AmrPlusPlus pipeline with Nextflow and Docker. This tutorial assumes you will be running the pipeline from a POSIX compatible system such as Linux, Solaris, or OS X. Setup We will go over a typical pipeline setup scenario in which you connect to a remote server, install Nextflow, and download the pipeline source code. For the easist use of AmrPlusPlus, make sure that Singularity is installed and in your $PATH variable. Visit this website for further information: https://singularity.lbl.gov/docs-installation If Singularity cannot be installed, configure the \"config/local.config\" file to specify the absolute PATH to each required bioinformatic tool. Then, change the flag after \"-profile\" to \"local\" when running the pipeline. # username and host address $ ssh [ USER ] @ [ HOST ] # Check if you have nextflow installed, $ nextflow -h # If not available, install Nextflow $ curl -s https://get.nextflow.io | bash # If you do not have curl installed, try wget # $ wget -qO- https://get.nextflow.io | bash # give write permissions to user $ chmod u+x nextflow # move nextflow executable to a folder in your PATH environment variable $ mv nextflow $HOME /bin # create a test directory and change into it $ mkdir amr_test && cd amr_test # clone pipeline source code $ git clone https://github.com/meglab-metagenomics/amrplusplus_v2.git . Run a Simple Test We will run a small sample dataset that comes with the pipeline source code. As such, we will not be specifying any input paths as they have already been included. During the program's execution, the required tool dependencies will be accessed using a Singularity container. As there are many tool dependencies, downloading the container could take some time depending on your connection speed. # navigate into AmrPlusPlus repository $ cd amrplusplus_v2/ # command to run the amrplusplus pipeline $ nextflow run main_AmrPlusPlus_v2.nf -profile singularity --output test_results # change directories to view pipeline outputs $ cd test/","title":"Installation"},{"location":"armplusplus/latest/installation/#installation","text":"This section will help you get started with running the AmrPlusPlus pipeline with Nextflow and Docker. This tutorial assumes you will be running the pipeline from a POSIX compatible system such as Linux, Solaris, or OS X.","title":"Installation"},{"location":"armplusplus/latest/installation/#setup","text":"We will go over a typical pipeline setup scenario in which you connect to a remote server, install Nextflow, and download the pipeline source code. For the easist use of AmrPlusPlus, make sure that Singularity is installed and in your $PATH variable. Visit this website for further information: https://singularity.lbl.gov/docs-installation If Singularity cannot be installed, configure the \"config/local.config\" file to specify the absolute PATH to each required bioinformatic tool. Then, change the flag after \"-profile\" to \"local\" when running the pipeline. # username and host address $ ssh [ USER ] @ [ HOST ] # Check if you have nextflow installed, $ nextflow -h # If not available, install Nextflow $ curl -s https://get.nextflow.io | bash # If you do not have curl installed, try wget # $ wget -qO- https://get.nextflow.io | bash # give write permissions to user $ chmod u+x nextflow # move nextflow executable to a folder in your PATH environment variable $ mv nextflow $HOME /bin # create a test directory and change into it $ mkdir amr_test && cd amr_test # clone pipeline source code $ git clone https://github.com/meglab-metagenomics/amrplusplus_v2.git .","title":"Setup"},{"location":"armplusplus/latest/installation/#run-a-simple-test","text":"We will run a small sample dataset that comes with the pipeline source code. As such, we will not be specifying any input paths as they have already been included. During the program's execution, the required tool dependencies will be accessed using a Singularity container. As there are many tool dependencies, downloading the container could take some time depending on your connection speed. # navigate into AmrPlusPlus repository $ cd amrplusplus_v2/ # command to run the amrplusplus pipeline $ nextflow run main_AmrPlusPlus_v2.nf -profile singularity --output test_results # change directories to view pipeline outputs $ cd test/","title":"Run a Simple Test"},{"location":"armplusplus/latest/introduction/","text":"Microbial Ecology Group (MEG) Our international multidisciplinary group of scientists and educators is addressing the issues of antimicrobial resistance (AMR) and microbial ecology in agriculture through research, outreach, and education. By characterizing risks related to AMR and microbial ecology, our center will identify agricultural production practices that are harmful and can be avoided, while also identifying and promoting production practices and interventions that are beneficial or do no harm to the ecosystem or public health. This will allow society to realize \u201csustainable intensification\u201d of agriculture. MEGARes and the AmrPlusPlus v2.0 bioinformatic pipeline The MEGARes database (https://megares.meglab.org/) contains sequence data for approximately 8,000 hand-curated antimicrobial resistance genes accompanied by an annotation structure that is optimized for use with high throughput sequencing and metagenomic analysis. The acyclical annotation graph of MEGARes allows for accurate, count-based, hierarchical statistical analysis of resistance at the population level, much like microbiome analysis, and is also designed to be used as a training database for the creation of statistical classifiers. The latest update in MEGARes 2.0 ( https://megares.meglab.org ) incorporates previously published resistance sequences for antimicrobial drugs, while also expanding to include published sequences for metal and biocide resistance determinants. The goal of many metagenomics studies is to characterize the content and relative abundance of sequences of interest from the DNA of a given sample or set of samples. You may want to know what is contained within your sample or how abundant a given sequence is relative to another. Often, metagenomics is performed when the answer to these questions must be obtained for a large number of targets where techniques like multiplex PCR and other targeted methods would be too cumbersome to perform. AmrPlusPlus v2.0 can process the raw data from the sequencer, identify the fragments of DNA, and count them. It also provides a count of the polymorphisms that occur in each DNA fragment with respect to the reference database. Additionally, you may want to know if the depth of your sequencing (how many reads you obtain that are on target) is high enough to identify rare organisms (organisms with low abundance relative to others) in your population. This is referred to as rarefaction and is calculated by randomly subsampling your sequence data at intervals between 0% and 100% in order to determine how many targets are found at each depth.With AmrPlusPlus v2.0, you will obtain alignment count files for each sample that can be combined into a count matrix and analyzed using any statistical and mathematical techniques that can operate on a matrix of observations.","title":"Introduction"},{"location":"armplusplus/latest/introduction/#microbial-ecology-group-meg","text":"Our international multidisciplinary group of scientists and educators is addressing the issues of antimicrobial resistance (AMR) and microbial ecology in agriculture through research, outreach, and education. By characterizing risks related to AMR and microbial ecology, our center will identify agricultural production practices that are harmful and can be avoided, while also identifying and promoting production practices and interventions that are beneficial or do no harm to the ecosystem or public health. This will allow society to realize \u201csustainable intensification\u201d of agriculture.","title":"Microbial Ecology Group (MEG)"},{"location":"armplusplus/latest/introduction/#megares-and-the-amrplusplus-v20-bioinformatic-pipeline","text":"The MEGARes database (https://megares.meglab.org/) contains sequence data for approximately 8,000 hand-curated antimicrobial resistance genes accompanied by an annotation structure that is optimized for use with high throughput sequencing and metagenomic analysis. The acyclical annotation graph of MEGARes allows for accurate, count-based, hierarchical statistical analysis of resistance at the population level, much like microbiome analysis, and is also designed to be used as a training database for the creation of statistical classifiers. The latest update in MEGARes 2.0 ( https://megares.meglab.org ) incorporates previously published resistance sequences for antimicrobial drugs, while also expanding to include published sequences for metal and biocide resistance determinants. The goal of many metagenomics studies is to characterize the content and relative abundance of sequences of interest from the DNA of a given sample or set of samples. You may want to know what is contained within your sample or how abundant a given sequence is relative to another. Often, metagenomics is performed when the answer to these questions must be obtained for a large number of targets where techniques like multiplex PCR and other targeted methods would be too cumbersome to perform. AmrPlusPlus v2.0 can process the raw data from the sequencer, identify the fragments of DNA, and count them. It also provides a count of the polymorphisms that occur in each DNA fragment with respect to the reference database. Additionally, you may want to know if the depth of your sequencing (how many reads you obtain that are on target) is high enough to identify rare organisms (organisms with low abundance relative to others) in your population. This is referred to as rarefaction and is calculated by randomly subsampling your sequence data at intervals between 0% and 100% in order to determine how many targets are found at each depth.With AmrPlusPlus v2.0, you will obtain alignment count files for each sample that can be combined into a count matrix and analyzed using any statistical and mathematical techniques that can operate on a matrix of observations.","title":"MEGARes and the AmrPlusPlus v2.0 bioinformatic pipeline"},{"location":"armplusplus/latest/output/","text":"Output All intermediate outputs produced from each module of this pipeline are provided as flat files that can be viewed in a text editor. These files are copied from the root work/ directory created by Nextflow, so if disk space is a concern, this directory should be deleted as it can get quite large. Directory Structure The output directories created by the pipeline are named after the module that produced them. Each file output is prefixed with the sample name and suffixed with a short product description. Files without sample prefixes are a result of aggregation. For example, the files host.removal.stats and trimmomatic.stats provide count matrices for the number of reads discarded as a result of host-dna removal and number of trimmed reads for each sample. \u251c\u2500\u2500 RunQC \u2502 \u251c\u2500\u2500 Paired \u2502 \u2502 \u251c\u2500\u2500 SRR532663.1P.fastq \u2502 \u2502 \u2514\u2500\u2500 SRR532663.2P.fastq \u2502 \u251c\u2500\u2500 Stats \u2502 \u2502 \u2514\u2500\u2500 trimmomatic.stats \u2502 \u2514\u2500\u2500 Unpaired \u2502 \u251c\u2500\u2500 SRR532663.1U.fastq \u2502 \u2514\u2500\u2500 SRR532663.2U.fastq \u251c\u2500\u2500 BuildHostIndex \u2502 \u251c\u2500\u2500 chr21.fasta.amb \u2502 \u251c\u2500\u2500 chr21.fasta.ann \u2502 \u251c\u2500\u2500 chr21.fasta.bwt \u2502 \u251c\u2500\u2500 chr21.fasta.pac \u2502 \u2514\u2500\u2500 chr21.fasta.sa \u251c\u2500\u2500 AlignReadsToHost \u2502 \u2514\u2500\u2500 SRR532663.host.sam \u251c\u2500\u2500 NonHostReads \u2502 \u251c\u2500\u2500 SRR532663.non.host.R1.fastq \u2502 \u2514\u2500\u2500 SRR532663.non.host.R2.fastq \u251c\u2500\u2500 RemoveHostDNA \u2502 \u251c\u2500\u2500 HostRemovalStats \u2502 \u2502 \u2514\u2500\u2500 host.removal.stats \u2502 \u2514\u2500\u2500 NonHostBAM \u2502 \u2514\u2500\u2500 SRR532663.host.sorted.removed.bam \u251c\u2500\u2500 AlignToAMR \u2502 \u2514\u2500\u2500 SRR532663.amr.alignment.sam \u251c\u2500\u2500 RunResistome \u2502 \u2514\u2500\u2500 SRR532663.gene.tsv \u251c\u2500\u2500 ResistomeResults \u2502 \u2514\u2500\u2500 AMR_analytic_matrix.csv \u251c\u2500\u2500 RunRarefaction \u2502 \u251c\u2500\u2500 SRR532663.class.tsv \u2502 \u251c\u2500\u2500 SRR532663.gene.tsv \u2502 \u251c\u2500\u2500 SRR532663.group.tsv \u2502 \u2514\u2500\u2500 SRR532663.mech.tsv \u251c\u2500\u2500 RunKraken \u2502 \u2514\u2500\u2500 SRR532663.kraken.report \u2502 \u2514\u2500\u2500 SRR532663.kraken.filtered.report \u251c\u2500\u2500 KrakenResults \u2502 \u2514\u2500\u2500 kraken_analytic_matrix.csv \u251c\u2500\u2500 FilteredKrakenResults \u2502 \u2514\u2500\u2500 filtered_kraken_analytic_matrix.csv","title":"Output"},{"location":"armplusplus/latest/output/#output","text":"All intermediate outputs produced from each module of this pipeline are provided as flat files that can be viewed in a text editor. These files are copied from the root work/ directory created by Nextflow, so if disk space is a concern, this directory should be deleted as it can get quite large.","title":"Output"},{"location":"armplusplus/latest/output/#directory-structure","text":"The output directories created by the pipeline are named after the module that produced them. Each file output is prefixed with the sample name and suffixed with a short product description. Files without sample prefixes are a result of aggregation. For example, the files host.removal.stats and trimmomatic.stats provide count matrices for the number of reads discarded as a result of host-dna removal and number of trimmed reads for each sample. \u251c\u2500\u2500 RunQC \u2502 \u251c\u2500\u2500 Paired \u2502 \u2502 \u251c\u2500\u2500 SRR532663.1P.fastq \u2502 \u2502 \u2514\u2500\u2500 SRR532663.2P.fastq \u2502 \u251c\u2500\u2500 Stats \u2502 \u2502 \u2514\u2500\u2500 trimmomatic.stats \u2502 \u2514\u2500\u2500 Unpaired \u2502 \u251c\u2500\u2500 SRR532663.1U.fastq \u2502 \u2514\u2500\u2500 SRR532663.2U.fastq \u251c\u2500\u2500 BuildHostIndex \u2502 \u251c\u2500\u2500 chr21.fasta.amb \u2502 \u251c\u2500\u2500 chr21.fasta.ann \u2502 \u251c\u2500\u2500 chr21.fasta.bwt \u2502 \u251c\u2500\u2500 chr21.fasta.pac \u2502 \u2514\u2500\u2500 chr21.fasta.sa \u251c\u2500\u2500 AlignReadsToHost \u2502 \u2514\u2500\u2500 SRR532663.host.sam \u251c\u2500\u2500 NonHostReads \u2502 \u251c\u2500\u2500 SRR532663.non.host.R1.fastq \u2502 \u2514\u2500\u2500 SRR532663.non.host.R2.fastq \u251c\u2500\u2500 RemoveHostDNA \u2502 \u251c\u2500\u2500 HostRemovalStats \u2502 \u2502 \u2514\u2500\u2500 host.removal.stats \u2502 \u2514\u2500\u2500 NonHostBAM \u2502 \u2514\u2500\u2500 SRR532663.host.sorted.removed.bam \u251c\u2500\u2500 AlignToAMR \u2502 \u2514\u2500\u2500 SRR532663.amr.alignment.sam \u251c\u2500\u2500 RunResistome \u2502 \u2514\u2500\u2500 SRR532663.gene.tsv \u251c\u2500\u2500 ResistomeResults \u2502 \u2514\u2500\u2500 AMR_analytic_matrix.csv \u251c\u2500\u2500 RunRarefaction \u2502 \u251c\u2500\u2500 SRR532663.class.tsv \u2502 \u251c\u2500\u2500 SRR532663.gene.tsv \u2502 \u251c\u2500\u2500 SRR532663.group.tsv \u2502 \u2514\u2500\u2500 SRR532663.mech.tsv \u251c\u2500\u2500 RunKraken \u2502 \u2514\u2500\u2500 SRR532663.kraken.report \u2502 \u2514\u2500\u2500 SRR532663.kraken.filtered.report \u251c\u2500\u2500 KrakenResults \u2502 \u2514\u2500\u2500 kraken_analytic_matrix.csv \u251c\u2500\u2500 FilteredKrakenResults \u2502 \u2514\u2500\u2500 filtered_kraken_analytic_matrix.csv","title":"Directory Structure"},{"location":"armplusplus/latest/references/","text":"References Bolger,A.M., Lohse,M. and Usadel,B. (2014) Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, 10.1093/bioinformatics/btu170. Li,H. (2013) Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. ArXiv13033997 Q-Bio. Quinlan,A.R. and Hall,I.M. (2010) BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26, 841\u2013842. Li,H., Handsaker,B., Wysoker,A., Fennell,T., Ruan,J., Homer,N., Marth,G., Abecasis,G., Durbin,R. and 1000 Genome Project Data Processing Subgroup (2009) The Sequence Alignment/Map format and SAMtools. Bioinforma. Oxf. Engl., 25, 2078\u20132079. Wood,D.E., Lu,J. and Langmead,B. (2019) Improved metagenomic analysis with Kraken 2. bioRxiv, 10.1101/762302. Nextflow programming language (https://www.nextflow.io/) Singularity: Scientific containers for mobility of compute. (https://singularity.lbl.gov/)","title":"References"},{"location":"armplusplus/latest/references/#references","text":"Bolger,A.M., Lohse,M. and Usadel,B. (2014) Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, 10.1093/bioinformatics/btu170. Li,H. (2013) Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. ArXiv13033997 Q-Bio. Quinlan,A.R. and Hall,I.M. (2010) BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26, 841\u2013842. Li,H., Handsaker,B., Wysoker,A., Fennell,T., Ruan,J., Homer,N., Marth,G., Abecasis,G., Durbin,R. and 1000 Genome Project Data Processing Subgroup (2009) The Sequence Alignment/Map format and SAMtools. Bioinforma. Oxf. Engl., 25, 2078\u20132079. Wood,D.E., Lu,J. and Langmead,B. (2019) Improved metagenomic analysis with Kraken 2. bioRxiv, 10.1101/762302. Nextflow programming language (https://www.nextflow.io/) Singularity: Scientific containers for mobility of compute. (https://singularity.lbl.gov/)","title":"References"},{"location":"armplusplus/latest/requirements/","text":"Software Requirements To run AmrPlusPlus, you will need the following libraries and tools installed on your server or local machine. Singularity Visit this website for further information: https://singularity.lbl.gov/docs-installation Java 7+ (Required) Nextflow (Required) Note If you choose not to install Singularity, you will need to download each of the required dependencies and add the executable paths to your .bashrc file to run the pipeline. A list of these dependencies can be found in the Dependencies section of this document.","title":"Software Requirements"},{"location":"armplusplus/latest/requirements/#software-requirements","text":"To run AmrPlusPlus, you will need the following libraries and tools installed on your server or local machine. Singularity Visit this website for further information: https://singularity.lbl.gov/docs-installation Java 7+ (Required) Nextflow (Required) Note If you choose not to install Singularity, you will need to download each of the required dependencies and add the executable paths to your .bashrc file to run the pipeline. A list of these dependencies can be found in the Dependencies section of this document.","title":"Software Requirements"},{"location":"armplusplus/latest/usage/","text":"Usage Display Help Message The help parameter displays the available options and commands. $ nextflow run main_AmrPlusPlus_v2.nf --help File Inputs Set custom sequence data The reads parameter accepts sequence files in standard fastq and gz format. $ nextflow run main_AmrPlusPlus_v2.nf --reads \"data/raw/*_R{1,2}.fastq\" Set host genome The host parameter accepts a fasta formatted host genome. $ nextflow run main_AmrPlusPlus_v2.nf --host \"data/host/chr21.fasta.gz\" Set host index The host_index parameter allows you to upload pre-built host indexes produced by BWA. $ nextflow run main_AmrPlusPlus_v2.nf --host \"data/host/chr21.fasta.gz\" --host_index \"data/index/*\" Set resistance database The amr parameter accepts a fasta formatted resistance database. $ nextflow run main_AmrPlusPlus_v2.nf --amr \"data/amr/megares_database_v1.02.fasta\" Set annotation database The annotation parameter accepts a csv formatted annotation database. $ nextflow run main_AmrPlusPlus_v2.nf --annotation \"data/amr/megares_annotations_v1.02.csv\" Set adapter file The adapters parameter accepts a fasta formatted adapter file. $ nextflow run main_AmrPlusPlus_v2.nf --adapters \"data/adapters/adapters.fa\" File Outputs Set output and work directories The output parameter writes the results to the specified directory. As a nextflow variable, the work parameter only requires one dash and determines where the temporary files will be directed. Upon completing the run, you can delete the temporary file directory. $ nextflow run main_AmrPlusPlus_v2.nf --output \"test/\" -work \"work_dir/\" Resume a pipeline run If the pipeline run is cancelled or stopped for whatever reason, using the same command with the addition of the -resume flag will attempt to pick up where the pipeline stopped. $ nextflow run main_AmrPlusPlus_v2.nf --output \"test/\" -work \"work_dir/\" -resume Trimming Options Set custom trimming parameters $ nextflow run main_AmrPlusPlus_v2.nf \\ --reads \"data/raw/*_R{1,2}.fastq\" \\ --leading 3 \\ --trailing 3 \\ --minlen 36 \\ --slidingwindow 4 \\ --adapters \"data/adapters/nextera.fa\" --output \"test/\" Algorithm Options Set custom algorithm options $ nextflow run main_AmrPlusPlus_v2.nf \\ --reads \"data/raw/*_R{1,2}.fastq\" \\ --threshold 80 \\ --min 1 \\ --max 100 \\ --samples 5 \\ --skip 5 \\ --output \"test/\" Set number of threads to use for each process $ nextflow run main_AmrPlusPlus_v2.nf --threads 8","title":"Usage"},{"location":"armplusplus/latest/usage/#usage","text":"","title":"Usage"},{"location":"armplusplus/latest/usage/#display-help-message","text":"The help parameter displays the available options and commands. $ nextflow run main_AmrPlusPlus_v2.nf --help","title":"Display Help Message"},{"location":"armplusplus/latest/usage/#file-inputs","text":"","title":"File Inputs"},{"location":"armplusplus/latest/usage/#set-custom-sequence-data","text":"The reads parameter accepts sequence files in standard fastq and gz format. $ nextflow run main_AmrPlusPlus_v2.nf --reads \"data/raw/*_R{1,2}.fastq\"","title":"Set custom sequence data"},{"location":"armplusplus/latest/usage/#set-host-genome","text":"The host parameter accepts a fasta formatted host genome. $ nextflow run main_AmrPlusPlus_v2.nf --host \"data/host/chr21.fasta.gz\"","title":"Set host genome"},{"location":"armplusplus/latest/usage/#set-host-index","text":"The host_index parameter allows you to upload pre-built host indexes produced by BWA. $ nextflow run main_AmrPlusPlus_v2.nf --host \"data/host/chr21.fasta.gz\" --host_index \"data/index/*\"","title":"Set host index"},{"location":"armplusplus/latest/usage/#set-resistance-database","text":"The amr parameter accepts a fasta formatted resistance database. $ nextflow run main_AmrPlusPlus_v2.nf --amr \"data/amr/megares_database_v1.02.fasta\"","title":"Set resistance database"},{"location":"armplusplus/latest/usage/#set-annotation-database","text":"The annotation parameter accepts a csv formatted annotation database. $ nextflow run main_AmrPlusPlus_v2.nf --annotation \"data/amr/megares_annotations_v1.02.csv\"","title":"Set annotation database"},{"location":"armplusplus/latest/usage/#set-adapter-file","text":"The adapters parameter accepts a fasta formatted adapter file. $ nextflow run main_AmrPlusPlus_v2.nf --adapters \"data/adapters/adapters.fa\"","title":"Set adapter file"},{"location":"armplusplus/latest/usage/#file-outputs","text":"","title":"File Outputs"},{"location":"armplusplus/latest/usage/#set-output-and-work-directories","text":"The output parameter writes the results to the specified directory. As a nextflow variable, the work parameter only requires one dash and determines where the temporary files will be directed. Upon completing the run, you can delete the temporary file directory. $ nextflow run main_AmrPlusPlus_v2.nf --output \"test/\" -work \"work_dir/\"","title":"Set output and work directories"},{"location":"armplusplus/latest/usage/#resume-a-pipeline-run","text":"If the pipeline run is cancelled or stopped for whatever reason, using the same command with the addition of the -resume flag will attempt to pick up where the pipeline stopped. $ nextflow run main_AmrPlusPlus_v2.nf --output \"test/\" -work \"work_dir/\" -resume","title":"Resume a pipeline run"},{"location":"armplusplus/latest/usage/#trimming-options","text":"","title":"Trimming Options"},{"location":"armplusplus/latest/usage/#set-custom-trimming-parameters","text":"$ nextflow run main_AmrPlusPlus_v2.nf \\ --reads \"data/raw/*_R{1,2}.fastq\" \\ --leading 3 \\ --trailing 3 \\ --minlen 36 \\ --slidingwindow 4 \\ --adapters \"data/adapters/nextera.fa\" --output \"test/\"","title":"Set custom trimming parameters"},{"location":"armplusplus/latest/usage/#algorithm-options","text":"","title":"Algorithm Options"},{"location":"armplusplus/latest/usage/#set-custom-algorithm-options","text":"$ nextflow run main_AmrPlusPlus_v2.nf \\ --reads \"data/raw/*_R{1,2}.fastq\" \\ --threshold 80 \\ --min 1 \\ --max 100 \\ --samples 5 \\ --skip 5 \\ --output \"test/\"","title":"Set custom algorithm options"},{"location":"armplusplus/latest/usage/#set-number-of-threads-to-use-for-each-process","text":"$ nextflow run main_AmrPlusPlus_v2.nf --threads 8","title":"Set number of threads to use for each process"},{"location":"armplusplus/v1/analysisoutput/","text":"What Does AmrPlusPlus Produce? Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. This section explains the files that you will receive after AmrPlusPlus is finished running. There are a total of 9 files: 4 resistome files, 4 rarefaction files, and 1 SNP file. The output used in the following sections is real output generated using the example data provided on the AmrPlusPlus website. 1. Resistome Analysis The resistome (counts of resistance genes found in your data) are generated in the following order: Note gene-level counts \u2192 Group-level counts \u2192 Mechanism-level counts \u2192 Class-level counts Four files are produced from this analysis step; each file corresponds to an annotation level in the MEGARes database: Class, Mechanism, Group, and gene (sequence-level). Because alignments were performed at the gene level, this file is the starting point for analysis. Within the file gene_level_resistome.tsv, each row represents a data entry, and there are four tab-separated columns. An example is provided below, and each field is individually explained: gene_level_resistome.tsv Sample Gene Hits Gene Fraction dataset_14 gi|13562034|gb|AF351241.1|betalactams|Class_A_betalactamases|TEM 5 32.3158 dataset_14 gi|14588992|emb|AJ277415.1|betalactams|Class_A_betalactamases|TEM 2 14.6341 dataset_14 gi|145975406|gb|EF534736.1|betalactams|Class_A_betalactamases|TEM 2 23.4637 dataset_14 gi|1488048|gb|U63835.1|PAU63835|betalactams|Class_D_betalactamases|OXA 1 10.678 dataset_14 gi|149167|gb|M88143.1|KPNBETALAC|betalactams|Class_A_betalactamases|TEM 1 9.93691 Sample: this is the sample ID to which the data belong and is typically related to the name of the input file. Gene: this field is the target gene from the MEGARes database (or whichever database you chose to use during alignment). These are the genes from the database that were found in your input data. If you're using MEGARes as a database, you can copy and paste the gene name into the MEGARes website search bar and it will provide additional information about that particular gene. Hits: this field is the number of short reads that aligned to that particular gene. We use this as a \u201ccount\u201d of how many times a given gene is \u201cseen\u201d in the data. These counts can be analyzed relative to counts of other genes. Gene Fraction: we define gene fraction as the percentage of the gene that is covered by at least one read. For example, if a gene has a fraction of 100%, then every nucleotide in that gene has at least one (or more) reads aligning to it. We use this field as a filter to reduce the number of false positives found in our output data. For instance, in the MEG lab, we do not count genes that have a fraction below 80%, so only genes that are covered more than 80% are used to generate counts for statistical analysis. The counts in this gene-level file are then aggregated up through the annotation graph to produce counts at the Group, then Mechanism, then Class level. In the example above, our next level up from gene is Group, and the Group file would look like so: group_level_resistome.tsv Sample Group Hits dataset_14 OXA 1 dataset_14 TEM 10 Note Fields are the same, except there is no Gene Fraction field in this file. Because alignment is performed on the genes, and the Gene Fraction information is calculated using alignment data, the gene-level file is the only one that contains Gene Fraction information. All genes that pass the Gene Fraction threshold will be counted into the next file at the Group level. Here, because we had two Groups represented in our lowest-level file, we see counts for two groups that are equal to the sum of the gene counts in the previous file. The next level up from Group is the Mechanism level, and the Mechanism file would look like so: mechanism_level_resistome.tsv Sample Mechanism Hits dataset_14 Class_D_betalactamases 1 dataset_14 Class_A_betalactamases 10 Because the TEM betalactamases are Ambler Class A betalactamases, their mechanism is \u201cClass_A_betalactamases\u201d. There are 10 counts for the Class A betalactamases because there were 10 counts for TEM in the Group file. Likewise, the OXA betalactamases are Ambler Class D, and therefore we see 1 count for Class D betalactamases in the Mechanism-level file. The next level up from Mechanism is the Class level, and the Class level file would look like so: class_level_resistome.tsv Sample Class Hits dataset_14 betalactams 11 The Class level is the highest level and includes the major drug classes of antimicrobial resistance. In this case, all of our counts were betalactamases, so we see that all 11 counts are now represented in the betalactams Class field. These four files comprise the output for the resistome analysis and can be combined across multiple samples to produce a count matrix for analysis. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. For suggestions on how to analyze and interpret count data, see the \u201cHow do I interpret the AmrPlusPlus output\u201d section. 2. Rarefaction Analysis Rarefaction is an ecological measure of how much of the biological diversity we have captured at a given sampling level. The generation of a rarefaction curve involves, for each sample, picking random sequences from that data and generating counts of how many unique genes were observed. Alternatively, we could ask how many unique Groups, Mechanisms, or Classes were observed at a given sampling level. RarefactionAnalyzer will take three random draws at increments of 5% sampling level, so 5% of the raw data, 10%, \u2026 , 100%. The number of unique genes, Groups, Mechanisms, and Classes are then plotted as a function of sampling depth. An example is provided here for our example data at the gene level. Ideally, we would see curves that flatten out toward the right-hand side of the graph (at the 100% sampling level), as this means that we have captured much of the diversity in our sample population. So for this particular figure, we have capture a lot of the diversity but could probably sample deeper in future studies. We largely obtain this result because our sample dataset is small for convenience of showcasing our pipeline. Real data will look slightly different. Rarefaction Gen Plot Graph How do I interpret the AmrPlusPlus output? At the conclusion of running AmrPlusPlus, you have four graphs, four files with counts, and a single file with SNP data from that sample. The graphs should be interpreted as described above for rarefaction analysis. View Gene Graph View Group Graph View Mechanism Graph View Class Graph The count data should be combined with other samples in your experiment into a count matrix. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. You can then use this count matrix as input for many statistical or descriptive procedures, including but not limitd to the following: Principal components analysis Non-metric multidimensional scaling Zero-inflated Gaussian Mixture Models (for example, with the metagenomeseq R package) Linear discriminant analysis The primary question that you'll want to ask of your data depends on your experimental design. However, this question usually involves some kind of comparison between groups: does group A have more betalactamases than group B? How does the resistome differ between group A and group B? Is that significant? What major features in group A make it significantly differ from group B? These kinds of questions are mostly statistical, and any tool that accepts count data can be used for further analysis. Because this is nearly identical to microbiome analysis, there are plenty of tools out there that can aid in further statistical exploration, such as the R package metagenomeseq .","title":"Example Analysis and Output"},{"location":"armplusplus/v1/analysisoutput/#what-does-amrplusplus-produce","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. This section explains the files that you will receive after AmrPlusPlus is finished running. There are a total of 9 files: 4 resistome files, 4 rarefaction files, and 1 SNP file. The output used in the following sections is real output generated using the example data provided on the AmrPlusPlus website.","title":"What Does AmrPlusPlus Produce?"},{"location":"armplusplus/v1/analysisoutput/#1-resistome-analysis","text":"The resistome (counts of resistance genes found in your data) are generated in the following order: Note gene-level counts \u2192 Group-level counts \u2192 Mechanism-level counts \u2192 Class-level counts Four files are produced from this analysis step; each file corresponds to an annotation level in the MEGARes database: Class, Mechanism, Group, and gene (sequence-level). Because alignments were performed at the gene level, this file is the starting point for analysis. Within the file gene_level_resistome.tsv, each row represents a data entry, and there are four tab-separated columns. An example is provided below, and each field is individually explained: gene_level_resistome.tsv Sample Gene Hits Gene Fraction dataset_14 gi|13562034|gb|AF351241.1|betalactams|Class_A_betalactamases|TEM 5 32.3158 dataset_14 gi|14588992|emb|AJ277415.1|betalactams|Class_A_betalactamases|TEM 2 14.6341 dataset_14 gi|145975406|gb|EF534736.1|betalactams|Class_A_betalactamases|TEM 2 23.4637 dataset_14 gi|1488048|gb|U63835.1|PAU63835|betalactams|Class_D_betalactamases|OXA 1 10.678 dataset_14 gi|149167|gb|M88143.1|KPNBETALAC|betalactams|Class_A_betalactamases|TEM 1 9.93691 Sample: this is the sample ID to which the data belong and is typically related to the name of the input file. Gene: this field is the target gene from the MEGARes database (or whichever database you chose to use during alignment). These are the genes from the database that were found in your input data. If you're using MEGARes as a database, you can copy and paste the gene name into the MEGARes website search bar and it will provide additional information about that particular gene. Hits: this field is the number of short reads that aligned to that particular gene. We use this as a \u201ccount\u201d of how many times a given gene is \u201cseen\u201d in the data. These counts can be analyzed relative to counts of other genes. Gene Fraction: we define gene fraction as the percentage of the gene that is covered by at least one read. For example, if a gene has a fraction of 100%, then every nucleotide in that gene has at least one (or more) reads aligning to it. We use this field as a filter to reduce the number of false positives found in our output data. For instance, in the MEG lab, we do not count genes that have a fraction below 80%, so only genes that are covered more than 80% are used to generate counts for statistical analysis. The counts in this gene-level file are then aggregated up through the annotation graph to produce counts at the Group, then Mechanism, then Class level. In the example above, our next level up from gene is Group, and the Group file would look like so: group_level_resistome.tsv Sample Group Hits dataset_14 OXA 1 dataset_14 TEM 10 Note Fields are the same, except there is no Gene Fraction field in this file. Because alignment is performed on the genes, and the Gene Fraction information is calculated using alignment data, the gene-level file is the only one that contains Gene Fraction information. All genes that pass the Gene Fraction threshold will be counted into the next file at the Group level. Here, because we had two Groups represented in our lowest-level file, we see counts for two groups that are equal to the sum of the gene counts in the previous file. The next level up from Group is the Mechanism level, and the Mechanism file would look like so: mechanism_level_resistome.tsv Sample Mechanism Hits dataset_14 Class_D_betalactamases 1 dataset_14 Class_A_betalactamases 10 Because the TEM betalactamases are Ambler Class A betalactamases, their mechanism is \u201cClass_A_betalactamases\u201d. There are 10 counts for the Class A betalactamases because there were 10 counts for TEM in the Group file. Likewise, the OXA betalactamases are Ambler Class D, and therefore we see 1 count for Class D betalactamases in the Mechanism-level file. The next level up from Mechanism is the Class level, and the Class level file would look like so: class_level_resistome.tsv Sample Class Hits dataset_14 betalactams 11 The Class level is the highest level and includes the major drug classes of antimicrobial resistance. In this case, all of our counts were betalactamases, so we see that all 11 counts are now represented in the betalactams Class field. These four files comprise the output for the resistome analysis and can be combined across multiple samples to produce a count matrix for analysis. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. For suggestions on how to analyze and interpret count data, see the \u201cHow do I interpret the AmrPlusPlus output\u201d section.","title":"1. Resistome Analysis"},{"location":"armplusplus/v1/analysisoutput/#2-rarefaction-analysis","text":"Rarefaction is an ecological measure of how much of the biological diversity we have captured at a given sampling level. The generation of a rarefaction curve involves, for each sample, picking random sequences from that data and generating counts of how many unique genes were observed. Alternatively, we could ask how many unique Groups, Mechanisms, or Classes were observed at a given sampling level. RarefactionAnalyzer will take three random draws at increments of 5% sampling level, so 5% of the raw data, 10%, \u2026 , 100%. The number of unique genes, Groups, Mechanisms, and Classes are then plotted as a function of sampling depth. An example is provided here for our example data at the gene level. Ideally, we would see curves that flatten out toward the right-hand side of the graph (at the 100% sampling level), as this means that we have captured much of the diversity in our sample population. So for this particular figure, we have capture a lot of the diversity but could probably sample deeper in future studies. We largely obtain this result because our sample dataset is small for convenience of showcasing our pipeline. Real data will look slightly different. Rarefaction Gen Plot Graph","title":"2. Rarefaction Analysis"},{"location":"armplusplus/v1/analysisoutput/#how-do-i-interpret-the-amrplusplus-output","text":"At the conclusion of running AmrPlusPlus, you have four graphs, four files with counts, and a single file with SNP data from that sample. The graphs should be interpreted as described above for rarefaction analysis. View Gene Graph View Group Graph View Mechanism Graph View Class Graph The count data should be combined with other samples in your experiment into a count matrix. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. You can then use this count matrix as input for many statistical or descriptive procedures, including but not limitd to the following: Principal components analysis Non-metric multidimensional scaling Zero-inflated Gaussian Mixture Models (for example, with the metagenomeseq R package) Linear discriminant analysis The primary question that you'll want to ask of your data depends on your experimental design. However, this question usually involves some kind of comparison between groups: does group A have more betalactamases than group B? How does the resistome differ between group A and group B? Is that significant? What major features in group A make it significantly differ from group B? These kinds of questions are mostly statistical, and any tool that accepts count data can be used for further analysis. Because this is nearly identical to microbiome analysis, there are plenty of tools out there that can aid in further statistical exploration, such as the R package metagenomeseq .","title":"How do I interpret the AmrPlusPlus output?"},{"location":"armplusplus/v1/citing/","text":"Citing AMR++ Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Lakin,S.M., Dean,C., Noyes,N.R., Dettenwanger,A., Ross,A.S., Doster,E., Rovira,P., Abdo,Z., Jones,K.L., Ruiz,J., et al. (2017) MEGARes: an antimicrobial resistance database for high throughput sequencing. Nucleic Acids Res., 45, D574\u2013D580.","title":"Citing AMR++"},{"location":"armplusplus/v1/citing/#citing-amr","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Lakin,S.M., Dean,C., Noyes,N.R., Dettenwanger,A., Ross,A.S., Doster,E., Rovira,P., Abdo,Z., Jones,K.L., Ruiz,J., et al. (2017) MEGARes: an antimicrobial resistance database for high throughput sequencing. Nucleic Acids Res., 45, D574\u2013D580.","title":"Citing AMR++"},{"location":"armplusplus/v1/contact/","text":"Contact Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Questions, bugs, or feature requests should be directed to meglab.metagenomics@gmail.com","title":"Contact"},{"location":"armplusplus/v1/contact/#contact","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Questions, bugs, or feature requests should be directed to meglab.metagenomics@gmail.com","title":"Contact"},{"location":"armplusplus/v1/introduction/","text":"AmrPlusPlus is an Easy to Use App that Identifies and Characterizes Resistance Genes within Sequence Data Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. AmrPlusPlus is a Galaxy-based metagenomics pipeline that is intuitive and easy to use. The pipeline takes advantage of current and new tools to help identify and characterize resistance genes within metagenomic sequence data. The pipeline can be used under a local instance of Galaxy 1,2,3 and installed via Galaxy's Main Tool Shed. It is also available as a Galaxy-based Docker Image, using base images developed by Bj\u00f6rn Gr\u00fcning at the University of Freiburg. We recommend checking out his Github repository . for other Galaxy tools and workflows. What's Included in the Installation? AmrPlusPlus consist of: Trimmomatic 4 (for removal of low quality bases and sequences), BWA 5 (for detection of host DNA and resistance genes), Samtools 6 (for removal of host DNA), SNPFinder (for detection of haplotypes), ResistomeAnalyzer (for resistome analysis). RarefactionAnalyzer (for rarefaction analysis) Together, these tools make up the entire AmrPlusPlus pipeline. Only three inputs are required to run the pipeline: a single or paired fastq dataset, a resistance database (fasta), and a host genome (fasta). What is the goal of AmrPlusPlus? The goal of many metagenomics studies is to characterize the content and relative abundance of sequences of interest from the DNA of a given sample or set of samples. You may want to know what is contained within your sample or how abundant a given sequence is relative to another. Often, metagenomics is performed when the answer to these questions must be obtained for a large number of targets where techniques like multiplex PCR and other targeted methods would be too cumbersome to perform. AmrPlusPlus can process the raw data from the sequencer, identify the fragments of DNA, and count them. It also provides a count of the polymorphisms that occur in each DNA fragment with respect to the reference database. Additionally, you may want to know if the depth of your sequencing (how many reads you obtain that are on target) is high enough to identify rare organisms (organisms with low abundance relative to others) in your population. This is referred to as rarefaction and is calculated by randomly subsampling your sequence data at intervals between 0% and 100% in order to determine how many targets are found at each depth. AmrPlusPlus can perform this analysis as well. As a result of AmrPlusPlus, you will obtain count files for each sample that can be combined into a count matrix and analyzed using any statistical and mathematical techniques that can operate on a matrix of observations. For an example of a study where we have performed this using metagenomic sequencing data, you can read the open access manuscript entitled \u201cResistome diversity in cattle and the environment decreases during beef production\u201d.","title":"Introduction"},{"location":"armplusplus/v1/introduction/#amrplusplus-is-an-easy-to-use-app-that-identifies-and-characterizes-resistance-genes-within-sequence-data","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. AmrPlusPlus is a Galaxy-based metagenomics pipeline that is intuitive and easy to use. The pipeline takes advantage of current and new tools to help identify and characterize resistance genes within metagenomic sequence data. The pipeline can be used under a local instance of Galaxy 1,2,3 and installed via Galaxy's Main Tool Shed. It is also available as a Galaxy-based Docker Image, using base images developed by Bj\u00f6rn Gr\u00fcning at the University of Freiburg. We recommend checking out his Github repository . for other Galaxy tools and workflows.","title":"AmrPlusPlus is an Easy to Use App that Identifies and Characterizes Resistance Genes within Sequence Data"},{"location":"armplusplus/v1/introduction/#whats-included-in-the-installation","text":"AmrPlusPlus consist of: Trimmomatic 4 (for removal of low quality bases and sequences), BWA 5 (for detection of host DNA and resistance genes), Samtools 6 (for removal of host DNA), SNPFinder (for detection of haplotypes), ResistomeAnalyzer (for resistome analysis). RarefactionAnalyzer (for rarefaction analysis) Together, these tools make up the entire AmrPlusPlus pipeline. Only three inputs are required to run the pipeline: a single or paired fastq dataset, a resistance database (fasta), and a host genome (fasta).","title":"What's Included in the Installation?"},{"location":"armplusplus/v1/introduction/#what-is-the-goal-of-amrplusplus","text":"The goal of many metagenomics studies is to characterize the content and relative abundance of sequences of interest from the DNA of a given sample or set of samples. You may want to know what is contained within your sample or how abundant a given sequence is relative to another. Often, metagenomics is performed when the answer to these questions must be obtained for a large number of targets where techniques like multiplex PCR and other targeted methods would be too cumbersome to perform. AmrPlusPlus can process the raw data from the sequencer, identify the fragments of DNA, and count them. It also provides a count of the polymorphisms that occur in each DNA fragment with respect to the reference database. Additionally, you may want to know if the depth of your sequencing (how many reads you obtain that are on target) is high enough to identify rare organisms (organisms with low abundance relative to others) in your population. This is referred to as rarefaction and is calculated by randomly subsampling your sequence data at intervals between 0% and 100% in order to determine how many targets are found at each depth. AmrPlusPlus can perform this analysis as well. As a result of AmrPlusPlus, you will obtain count files for each sample that can be combined into a count matrix and analyzed using any statistical and mathematical techniques that can operate on a matrix of observations. For an example of a study where we have performed this using metagenomic sequencing data, you can read the open access manuscript entitled \u201cResistome diversity in cattle and the environment decreases during beef production\u201d.","title":"What is the goal of AmrPlusPlus?"},{"location":"armplusplus/v1/references/","text":"References Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Goecks, J, Nekrutenko, A, Taylor, J and The Galaxy Team. Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences. Genome Biol. 2010 Aug 25;11(8):R86. Blankenberg D, Von Kuster G, Coraor N, Ananda G, Lazarus R, Mangan M, Nekrutenko A, Taylor J. \"Galaxy: a web-based genome analysis tool for experimentalists\". Current Protocols in Molecular Biology. 2010 Jan; Chapter 19:Unit 19.10.1-21. Giardine B, Riemer C, Hardison RC, Burhans R, Elnitski L, Shah P, Zhang Y, Blankenberg D, Albert I, Taylor J, Miller W, Kent WJ, Nekrutenko A. \"Galaxy: a platform for interactive large-scale genome analysis.\" Genome Research. 2005 Oct; 15(10):1451-5. Bolger, A. M., Lohse, M., & Usadel, B. (2014). Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, btu170. Li H. and Durbin R. (2009) Fast and accurate short read alignment with Burrows-Wheeler Transform. Bioinformatics, 25:1754-60. Li H, Handsaker B, Wysoker A, et al. The Sequence Alignment/Map format and SAMtools. Bioinformatics. 2009;25(16):2078-2079. doi:10.1093/bioinformatics/btp352.","title":"References"},{"location":"armplusplus/v1/references/#references","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Goecks, J, Nekrutenko, A, Taylor, J and The Galaxy Team. Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences. Genome Biol. 2010 Aug 25;11(8):R86. Blankenberg D, Von Kuster G, Coraor N, Ananda G, Lazarus R, Mangan M, Nekrutenko A, Taylor J. \"Galaxy: a web-based genome analysis tool for experimentalists\". Current Protocols in Molecular Biology. 2010 Jan; Chapter 19:Unit 19.10.1-21. Giardine B, Riemer C, Hardison RC, Burhans R, Elnitski L, Shah P, Zhang Y, Blankenberg D, Albert I, Taylor J, Miller W, Kent WJ, Nekrutenko A. \"Galaxy: a platform for interactive large-scale genome analysis.\" Genome Research. 2005 Oct; 15(10):1451-5. Bolger, A. M., Lohse, M., & Usadel, B. (2014). Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, btu170. Li H. and Durbin R. (2009) Fast and accurate short read alignment with Burrows-Wheeler Transform. Bioinformatics, 25:1754-60. Li H, Handsaker B, Wysoker A, et al. The Sequence Alignment/Map format and SAMtools. Bioinformatics. 2009;25(16):2078-2079. doi:10.1093/bioinformatics/btp352.","title":"References"},{"location":"armplusplus/v1/documentation/docker/","text":"Docker Commands Reference Guide Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Overview Below, we will cover some of the basic Docker commands that you will find useful when interacting with Docker containers. Many of these commands can be found on the Docker commands homepage and from the Galaxy Docker Github repository. They are simply reviewed here for convenience. Container Commands Runs the chrisd/amrplusplus container in the background with no FTP server $ docker run -d -p 8080:80 chrisd/amrplusplus Runs the chrisd/amrplusplus container in the background with an FTP server $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Provides information about currently running containers $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6296a2688b71 chrisd/amrplusplus \"/usr/bin/startup\" 10 hours ago Up 10 hours 8800/tcp, 9002/tcp, 0.0.0.0:8021->21/tcp, 0.0.0.0:8080->80/tcp elated_cray Stops the currently running container specified by the CONTAINER ID $ docker stop 6296a2688b71 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Provides information about currently saved images $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE chrisd/amrplusplus latest 976681113852 3 days ago 1.623 GB Interact with a running container You will be launched into a Bash shell and allowed to explore the container. $ docker run -i -t -p 8080:80 chrisd/amrplusplus /bin/bash root@d49e4fa1bd22:/galaxy-central# Give a running Galaxy container persistent storage By DEFAULT, Galaxy containers are volatile, meaning that once they are stopped, all data and uploaded files will be removed. This command can be used to give a running Galaxy container persistent storage $ docker run -d -p 8080:80 -v /home/user/galaxy_storage/:/export/ chrisd/amrplusplus","title":"Docker Commands"},{"location":"armplusplus/v1/documentation/docker/#docker-commands-reference-guide","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs.","title":"Docker Commands Reference Guide"},{"location":"armplusplus/v1/documentation/docker/#overview","text":"Below, we will cover some of the basic Docker commands that you will find useful when interacting with Docker containers. Many of these commands can be found on the Docker commands homepage and from the Galaxy Docker Github repository. They are simply reviewed here for convenience.","title":"Overview"},{"location":"armplusplus/v1/documentation/docker/#container-commands","text":"Runs the chrisd/amrplusplus container in the background with no FTP server $ docker run -d -p 8080:80 chrisd/amrplusplus Runs the chrisd/amrplusplus container in the background with an FTP server $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Provides information about currently running containers $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6296a2688b71 chrisd/amrplusplus \"/usr/bin/startup\" 10 hours ago Up 10 hours 8800/tcp, 9002/tcp, 0.0.0.0:8021->21/tcp, 0.0.0.0:8080->80/tcp elated_cray Stops the currently running container specified by the CONTAINER ID $ docker stop 6296a2688b71 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Provides information about currently saved images $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE chrisd/amrplusplus latest 976681113852 3 days ago 1.623 GB Interact with a running container You will be launched into a Bash shell and allowed to explore the container. $ docker run -i -t -p 8080:80 chrisd/amrplusplus /bin/bash root@d49e4fa1bd22:/galaxy-central# Give a running Galaxy container persistent storage By DEFAULT, Galaxy containers are volatile, meaning that once they are stopped, all data and uploaded files will be removed. This command can be used to give a running Galaxy container persistent storage $ docker run -d -p 8080:80 -v /home/user/galaxy_storage/:/export/ chrisd/amrplusplus","title":"Container Commands"},{"location":"armplusplus/v1/documentation/pipeline/","text":"Pipeline Description Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Below we explain the use of each component in the AmrPlusPlus pipeline. Step 1: Input Input The raw data input to AmrPlusPlus will be a single pair of fastq files, one forward and one reverse. Additionally, you will need a database file in FASTA format (for the targets you wish to find in your data) such as the MEGARes database file, and a FASTA file for a host organism. Step 2: Quality Control Quality Control Depending on the sequencing platform, your data will likely contain some kind of error or bias. For Illumina sequencers, the quality of the sequence (the confidence that a given nucleotide is correct) drops off toward the end of the read. For Proton Torrent machines, there will be tandem repeats of nucleotides that aren't correct. Additionally, random error will be dispersed throughout. Quality control programs utilize statistics and other mathematical conventions to remove these regions of error from your data. While it is not necessarily required, it is highly recommended to run a quality control program on your raw data, as it is fairly efficient and will give you information about the quality of the sequencing performed on your samples. Ideally, less than 10% of the data will be of poor quality. For AmrPlusPlus, we use Trimmomatic 4 to perform quality control. Step 3: Removal of Host DNA Removal of Host DNA If your samples are collected from an animal source, there will be DNA that is off-target in your sample. We define off-target as being a sequence that is not contained within the database of interest, so for our typical use case, this would be any DNA that is not related to antimicrobial resistance. While it is not required to perform this step, it is recommended, as it can reduce the rate of false positive classifications. Reviewers have also commented on the quality of the pipeline when this step has been left out in our previous manuscripts, so we now perform host removal on all samples. We use the Burrows Wheeler Aligner 5 and a FASTA file of known host genetic sequences to match reads from the sample to the host genome. We then utilize Samtools 6 to filter out the reads that align to the host genome. Step 4: Alignment to Target Database Alignment to Target Database This step is the same as the prior step, except we use the database of interest for alignment. This will match the raw short read sequences to the target database using BWA and provide a SAM file as output. SAM stands for Sequence Alignment/Map and provides information for how the short fragments map to the database sequences; the SAM file specification is fairly detailed, so these files are large and often contain information that isn't useful in many contexts. We have written programs to parse this file and obtain the information of interest about the aligned reads. Step 5: Resistome Analysis Resistome Analysis This part of the pipeline takes the SAM file generated in Step 4 and transforms it into the sample resistome. It does this by counting each alignment for each gene found in the SAM file (1 aligned read = 1 count). The output consists of 4 tab-delimited text files, one for each level of the database hierarchy (gene, group, mechanism and class). Within each file, the first column lists the sample that was analyzed (taken from the file name), the second column lists the gene, group, mechanism or class that was identified, and the third column gives the total count of reads that aligned to that gene, group, mechanism or class. For the gene-level output, there is a fourth column that lists the gene fraction. Gene fraction is defined as the proportion of nucleotides in the reference sequence that were aligned to by at least one sequence read. Our program allows you to set a gene fraction threshold at which genes are considered to be positively identified in the sample. This threshold is meant to decrease false positive identification. For example, if you set the gene fraction threshold at 80%, then only genes with at least 80% nucleotide coverage will be included in the output. Step 6: Rarefaction Analysis Rarefaction Analysis If a rarefaction analysis is desired, our program called RarefactionAnalyzer can perform it at this step. Rarefaction can be of interest when you wish to know the fraction of the target population that is captured in your sequence data versus the fraction of the target population that has not been described due to not sequencing deep enough. This is a standard analysis performed for microbiome research and is typically recommended for any kind of metagenomics where counts are of interest. Using our program, you are able to specify the increments (i.e., \"levels\") of your rarefaction (i.e., whether you subsample your sequence data in 5-percent increments, 20-percent increments, etc...), and the number of random subsamples (i.e., \"iterations\") to perform at each increment. In order to obtain a smooth rarefaction curve, we suggest performing at least 5 iterations at each level so that each point on the curve is an average of at least 5 random subsamples. In addition to setting the \"level\" and \"iteration\" parameters, you are also able to apply a gene fraction threshold to the rarefaction analysis (see Step 5 for more details). The output of the Rarefaction Analysis includes 4 rarefaction curves -- one for each level of the annotation hierarchy (gene, group, mechanism and class). For each graph, the x-axis is the rarefaction level (from 0 to 100%), and the y-axis is the number of unique genes, group, mechanisms or classes identified in the rarefied data. Step 7: Read-pair Haplotyping Read-pair Haplotyping Variants are defined as nucleotides that differ from the reference database target. For reads that have aligned to a given reference sequence, we check each nucleotide against the reference target to determine if a variant is present. If multiple variants are present on the same read pair, we can make the assumption that they come from the same fragment of DNA (the same organism), so we record these variants that fall on the same read pair as haplotypes. The output from the variant calling step is a count file similar to the Resistome Analysis step, however the counts are of the haplotypes as determined with respect to the reference target. This information can be used in statistical analysis of counts, as in the previous step, or variants of interest can be manually found in the file if they are of interest. Output from this module is a tab delimited text file with three columns: Gene: Name of the gene that contains the corresponding haplotype Haplotype Pattern: Location(s) of each SNP, followed by reference nucleotide -> variant nucleotide. SNP locations and variants are separated by full colons. Occurrence: The number of reads (or read pairs) with the given haplotype pattern. Output Gene Haplotype Pattern Occurrence gene1 494T->A:987C->A:1001A->T 2 gene2 56T->A:80A->C:93A->C:109T->A 8 gene3 285T->A:1022:C->G 3 gene4 585T->A:1051:C->A 1 Output As output from running AmrPlusPlus, you will receive two files for each sample: a file with a count of how many reads aligned to each target from the reference database, and a file with a count of haplotypes that were detected within aligned reads. Our recommendation is to then combine files of the same type into two \u201cmaster\u201d files that are count matrices. Depending on the subsequent application you will be using for statistical analysis, you may want to arrange the matrices with gene targets as rows and the samples as columns, where the counts of the targets are the entries in the matrix. Alternatively, you could transpose that matrix and have the gene targets be the columns and the samples be the rows. Next Steps With the two count matrices, you can then perform statistical analyses using publicly available tools. We make use of the R programming language and the package metagenomeseq to perform a count matrix analysis. The questions that are typically asked of count data are: How similar or different are the samples, both by pairwise comparison and by study design? If there is a time series in the experimental design, is there a significant trend over time related to the count data? Are the statistically significant differences related to any biologically meaningful group of targets? The metagenomeseq package can perform the analyses in (1) and (2), and the user can obtain information about (3) based on the results. Another option, if relative abundance changes are of interest, is to use an RNA-seq count matrix analysis package such as DESeq2 (also an R package) to gather statistics on the log-fold changes from one sample group to another.","title":"Pipeline Description"},{"location":"armplusplus/v1/documentation/pipeline/#pipeline-description","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Below we explain the use of each component in the AmrPlusPlus pipeline. Step 1: Input","title":"Pipeline Description"},{"location":"armplusplus/v1/documentation/pipeline/#input","text":"The raw data input to AmrPlusPlus will be a single pair of fastq files, one forward and one reverse. Additionally, you will need a database file in FASTA format (for the targets you wish to find in your data) such as the MEGARes database file, and a FASTA file for a host organism. Step 2: Quality Control","title":"Input"},{"location":"armplusplus/v1/documentation/pipeline/#quality-control","text":"Depending on the sequencing platform, your data will likely contain some kind of error or bias. For Illumina sequencers, the quality of the sequence (the confidence that a given nucleotide is correct) drops off toward the end of the read. For Proton Torrent machines, there will be tandem repeats of nucleotides that aren't correct. Additionally, random error will be dispersed throughout. Quality control programs utilize statistics and other mathematical conventions to remove these regions of error from your data. While it is not necessarily required, it is highly recommended to run a quality control program on your raw data, as it is fairly efficient and will give you information about the quality of the sequencing performed on your samples. Ideally, less than 10% of the data will be of poor quality. For AmrPlusPlus, we use Trimmomatic 4 to perform quality control. Step 3: Removal of Host DNA","title":"Quality Control"},{"location":"armplusplus/v1/documentation/pipeline/#removal-of-host-dna","text":"If your samples are collected from an animal source, there will be DNA that is off-target in your sample. We define off-target as being a sequence that is not contained within the database of interest, so for our typical use case, this would be any DNA that is not related to antimicrobial resistance. While it is not required to perform this step, it is recommended, as it can reduce the rate of false positive classifications. Reviewers have also commented on the quality of the pipeline when this step has been left out in our previous manuscripts, so we now perform host removal on all samples. We use the Burrows Wheeler Aligner 5 and a FASTA file of known host genetic sequences to match reads from the sample to the host genome. We then utilize Samtools 6 to filter out the reads that align to the host genome. Step 4: Alignment to Target Database","title":"Removal of Host DNA"},{"location":"armplusplus/v1/documentation/pipeline/#alignment-to-target-database","text":"This step is the same as the prior step, except we use the database of interest for alignment. This will match the raw short read sequences to the target database using BWA and provide a SAM file as output. SAM stands for Sequence Alignment/Map and provides information for how the short fragments map to the database sequences; the SAM file specification is fairly detailed, so these files are large and often contain information that isn't useful in many contexts. We have written programs to parse this file and obtain the information of interest about the aligned reads. Step 5: Resistome Analysis","title":"Alignment to Target Database"},{"location":"armplusplus/v1/documentation/pipeline/#resistome-analysis","text":"This part of the pipeline takes the SAM file generated in Step 4 and transforms it into the sample resistome. It does this by counting each alignment for each gene found in the SAM file (1 aligned read = 1 count). The output consists of 4 tab-delimited text files, one for each level of the database hierarchy (gene, group, mechanism and class). Within each file, the first column lists the sample that was analyzed (taken from the file name), the second column lists the gene, group, mechanism or class that was identified, and the third column gives the total count of reads that aligned to that gene, group, mechanism or class. For the gene-level output, there is a fourth column that lists the gene fraction. Gene fraction is defined as the proportion of nucleotides in the reference sequence that were aligned to by at least one sequence read. Our program allows you to set a gene fraction threshold at which genes are considered to be positively identified in the sample. This threshold is meant to decrease false positive identification. For example, if you set the gene fraction threshold at 80%, then only genes with at least 80% nucleotide coverage will be included in the output. Step 6: Rarefaction Analysis","title":"Resistome Analysis"},{"location":"armplusplus/v1/documentation/pipeline/#rarefaction-analysis","text":"If a rarefaction analysis is desired, our program called RarefactionAnalyzer can perform it at this step. Rarefaction can be of interest when you wish to know the fraction of the target population that is captured in your sequence data versus the fraction of the target population that has not been described due to not sequencing deep enough. This is a standard analysis performed for microbiome research and is typically recommended for any kind of metagenomics where counts are of interest. Using our program, you are able to specify the increments (i.e., \"levels\") of your rarefaction (i.e., whether you subsample your sequence data in 5-percent increments, 20-percent increments, etc...), and the number of random subsamples (i.e., \"iterations\") to perform at each increment. In order to obtain a smooth rarefaction curve, we suggest performing at least 5 iterations at each level so that each point on the curve is an average of at least 5 random subsamples. In addition to setting the \"level\" and \"iteration\" parameters, you are also able to apply a gene fraction threshold to the rarefaction analysis (see Step 5 for more details). The output of the Rarefaction Analysis includes 4 rarefaction curves -- one for each level of the annotation hierarchy (gene, group, mechanism and class). For each graph, the x-axis is the rarefaction level (from 0 to 100%), and the y-axis is the number of unique genes, group, mechanisms or classes identified in the rarefied data. Step 7: Read-pair Haplotyping","title":"Rarefaction Analysis"},{"location":"armplusplus/v1/documentation/pipeline/#read-pair-haplotyping","text":"Variants are defined as nucleotides that differ from the reference database target. For reads that have aligned to a given reference sequence, we check each nucleotide against the reference target to determine if a variant is present. If multiple variants are present on the same read pair, we can make the assumption that they come from the same fragment of DNA (the same organism), so we record these variants that fall on the same read pair as haplotypes. The output from the variant calling step is a count file similar to the Resistome Analysis step, however the counts are of the haplotypes as determined with respect to the reference target. This information can be used in statistical analysis of counts, as in the previous step, or variants of interest can be manually found in the file if they are of interest. Output from this module is a tab delimited text file with three columns: Gene: Name of the gene that contains the corresponding haplotype Haplotype Pattern: Location(s) of each SNP, followed by reference nucleotide -> variant nucleotide. SNP locations and variants are separated by full colons. Occurrence: The number of reads (or read pairs) with the given haplotype pattern. Output Gene Haplotype Pattern Occurrence gene1 494T->A:987C->A:1001A->T 2 gene2 56T->A:80A->C:93A->C:109T->A 8 gene3 285T->A:1022:C->G 3 gene4 585T->A:1051:C->A 1 Output As output from running AmrPlusPlus, you will receive two files for each sample: a file with a count of how many reads aligned to each target from the reference database, and a file with a count of haplotypes that were detected within aligned reads. Our recommendation is to then combine files of the same type into two \u201cmaster\u201d files that are count matrices. Depending on the subsequent application you will be using for statistical analysis, you may want to arrange the matrices with gene targets as rows and the samples as columns, where the counts of the targets are the entries in the matrix. Alternatively, you could transpose that matrix and have the gene targets be the columns and the samples be the rows. Next Steps With the two count matrices, you can then perform statistical analyses using publicly available tools. We make use of the R programming language and the package metagenomeseq to perform a count matrix analysis. The questions that are typically asked of count data are: How similar or different are the samples, both by pairwise comparison and by study design? If there is a time series in the experimental design, is there a significant trend over time related to the count data? Are the statistically significant differences related to any biologically meaningful group of targets? The metagenomeseq package can perform the analyses in (1) and (2), and the user can obtain information about (3) based on the results. Another option, if relative abundance changes are of interest, is to use an RNA-seq count matrix analysis package such as DESeq2 (also an R package) to gather statistics on the log-fold changes from one sample group to another.","title":"Read-pair Haplotyping"},{"location":"armplusplus/v1/documentation/usermanual/","text":"Workflow Parameters Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Parameters for each of the workflow components within the AmrPlusPlus pipeline can be customized by the user. Here, we provide detailed descriptions for each of the input parameters for SNPFinder and CoverageSampler. It may be desirable to set custom inputs for tools like Trimmomatic 4 and Burrows Wheeler Aligner 5 . If you wish to do so, please see the Trimmomatic User Manual , as well as the BWA User Manual before doing so. SNPFinder SNPFinder Filter on unique alignments SNPFinder only has one user defined parameter. In order to understand this parameter, we need to understand BWA's behavior. When BWA finds a read that aligns equally well to multiple resistance genes, it flags that read as having multiple alignments. By default, SNPFinder will include those reads when identifying haplotypes, however if you want to only consider reads with single alignments, check the box under Filter on unique alignments . Rarefaction Analyzer Rarefaction Analyzer Perform both rarefaction and calculation of gene fraction. Depending on what type of analysis you want to do, you can change the parameters to fit your needs. Below, we describe some common usage scenarios. Starting sample level If you want to perform rarefaction on your data, this would be the lowest rarefaction level. For example, if you want to rarefy your data down to 5% of the total you would input 5. However, if you only want to look at all of the alignments in your data (and not rarefaction), then set this parameter to 100. Ending sample level If you want to perform rarefaction on your data, this would be the highest rarefaction level. For example, if you want to rarefy your data from 5% to 95% of the total, you would input 5% for the \"starting sample level\" and 95% for the ending sample level. However, if you only want to look at all of the alignments in your data (and not perform rarefaction), then set this to 100. Gene fraction threshold This is the thresold for identifying \"positives\" within your sample. For instance, if you only want to identify genes that have at least 1 read aligning to at least 80% of their bases, then you would set this to 80. If you want to identify only those genes that are completely aligned across their entire length, set this to 100. If you want to identify all hits to all genes, then set this to 0. Amount of sample levels to skip If you are performing rarefaction, this sets the increments for the rarefaction. For example, if you want to rarefy from 5% to 95% of your data in increments of 5% points, then set this to 5. In this example, you would then get all of the genes identified for 5, 10, 15, 20, ..., 90, 95% of your data. If you only want to look at all of the alignments in your data and not perform rarefaction, then set this parameter to 1. Iterations per sample level If you are performing rarefaction, and you want to produce an average for each rarefaction level, you can specify here how many samplings you want to perform at each rarefaction level. For instance, if you set this to 10, and \"starting sample level\", \"ending sample level\" and \"amount of sample levels to skip\" are set to 5, 95 and 5, respectively, then the program will perform 10 unique subsamples of the data at the 5% level, 10 at the 10% level, 10 at the 15% level, etc.. You can then average the output from each subsample at each level in order to get a smooth rarefaction curve for your data.","title":"User Manual (Options and Settings)"},{"location":"armplusplus/v1/documentation/usermanual/#workflow-parameters","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Parameters for each of the workflow components within the AmrPlusPlus pipeline can be customized by the user. Here, we provide detailed descriptions for each of the input parameters for SNPFinder and CoverageSampler. It may be desirable to set custom inputs for tools like Trimmomatic 4 and Burrows Wheeler Aligner 5 . If you wish to do so, please see the Trimmomatic User Manual , as well as the BWA User Manual before doing so.","title":"Workflow Parameters"},{"location":"armplusplus/v1/documentation/usermanual/#snpfinder","text":"SNPFinder","title":"SNPFinder"},{"location":"armplusplus/v1/documentation/usermanual/#filter-on-unique-alignments","text":"SNPFinder only has one user defined parameter. In order to understand this parameter, we need to understand BWA's behavior. When BWA finds a read that aligns equally well to multiple resistance genes, it flags that read as having multiple alignments. By default, SNPFinder will include those reads when identifying haplotypes, however if you want to only consider reads with single alignments, check the box under Filter on unique alignments .","title":"Filter on unique alignments"},{"location":"armplusplus/v1/documentation/usermanual/#rarefaction-analyzer","text":"Rarefaction Analyzer","title":"Rarefaction Analyzer"},{"location":"armplusplus/v1/documentation/usermanual/#perform-both-rarefaction-and-calculation-of-gene-fraction","text":"Depending on what type of analysis you want to do, you can change the parameters to fit your needs. Below, we describe some common usage scenarios.","title":"Perform both rarefaction and calculation of gene fraction."},{"location":"armplusplus/v1/documentation/usermanual/#starting-sample-level","text":"If you want to perform rarefaction on your data, this would be the lowest rarefaction level. For example, if you want to rarefy your data down to 5% of the total you would input 5. However, if you only want to look at all of the alignments in your data (and not rarefaction), then set this parameter to 100.","title":"Starting sample level"},{"location":"armplusplus/v1/documentation/usermanual/#ending-sample-level","text":"If you want to perform rarefaction on your data, this would be the highest rarefaction level. For example, if you want to rarefy your data from 5% to 95% of the total, you would input 5% for the \"starting sample level\" and 95% for the ending sample level. However, if you only want to look at all of the alignments in your data (and not perform rarefaction), then set this to 100.","title":"Ending sample level"},{"location":"armplusplus/v1/documentation/usermanual/#gene-fraction-threshold","text":"This is the thresold for identifying \"positives\" within your sample. For instance, if you only want to identify genes that have at least 1 read aligning to at least 80% of their bases, then you would set this to 80. If you want to identify only those genes that are completely aligned across their entire length, set this to 100. If you want to identify all hits to all genes, then set this to 0.","title":"Gene fraction threshold"},{"location":"armplusplus/v1/documentation/usermanual/#amount-of-sample-levels-to-skip","text":"If you are performing rarefaction, this sets the increments for the rarefaction. For example, if you want to rarefy from 5% to 95% of your data in increments of 5% points, then set this to 5. In this example, you would then get all of the genes identified for 5, 10, 15, 20, ..., 90, 95% of your data. If you only want to look at all of the alignments in your data and not perform rarefaction, then set this parameter to 1.","title":"Amount of sample levels to skip"},{"location":"armplusplus/v1/documentation/usermanual/#iterations-per-sample-level","text":"If you are performing rarefaction, and you want to produce an average for each rarefaction level, you can specify here how many samplings you want to perform at each rarefaction level. For instance, if you set this to 10, and \"starting sample level\", \"ending sample level\" and \"amount of sample levels to skip\" are set to 5, 95 and 5, respectively, then the program will perform 10 unique subsamples of the data at the 5% level, 10 at the 10% level, 10 at the 15% level, etc.. You can then average the output from each subsample at each level in order to get a smooth rarefaction curve for your data.","title":"Iterations per sample level"},{"location":"armplusplus/v1/running/runworkflow/","text":"Run AMR++ Workflow Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Now that we've got our data uploaded to our Galaxy server, it's time to run the workflow. Step 1: Navigate to the Workflow Tab Navigate to the Workflow Tab See the workflow tab circled in red below on the Galaxy homepage: Then click on the workflow you imported earlier and select Run You will be redirected to a page (see below) displaying each component of the workflow. Step 2: Select the Datasets Select the Datasets First, select the forward read pair. Then, select the second read pair. Next, select the host genome and resistance database. If you wish to customize any of the workflow components, please see the Workflow Parameters section before proceeding. Once the datasets have been selected, simply click the Run workflow button (circled in red). Step 3: View the Outputs View the Outputs When the workflow completes, you can find all intermediate and final outputs in the Galaxy history pane. The outputs you will be most interested in come from the SNPFinder and CoverageSampler modules. To view the outputs, simply click on the view data icon (circled in red). Once the datasets have been selected, simply click the Run workflow button (circled in red). These outputs can then be downloaded to your local machine by clicking on the download icon (circled in red). For more information on interpreting the output from each of these tools, please see the CoverageSampler and SNPFinder output descriptions.","title":"Run AMR++ Workflow"},{"location":"armplusplus/v1/running/runworkflow/#run-amr-workflow","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Now that we've got our data uploaded to our Galaxy server, it's time to run the workflow. Step 1: Navigate to the Workflow Tab","title":"Run AMR++ Workflow"},{"location":"armplusplus/v1/running/runworkflow/#navigate-to-the-workflow-tab","text":"See the workflow tab circled in red below on the Galaxy homepage: Then click on the workflow you imported earlier and select Run You will be redirected to a page (see below) displaying each component of the workflow. Step 2: Select the Datasets","title":"Navigate to the Workflow Tab"},{"location":"armplusplus/v1/running/runworkflow/#select-the-datasets","text":"First, select the forward read pair. Then, select the second read pair. Next, select the host genome and resistance database. If you wish to customize any of the workflow components, please see the Workflow Parameters section before proceeding. Once the datasets have been selected, simply click the Run workflow button (circled in red). Step 3: View the Outputs","title":"Select the Datasets"},{"location":"armplusplus/v1/running/runworkflow/#view-the-outputs","text":"When the workflow completes, you can find all intermediate and final outputs in the Galaxy history pane. The outputs you will be most interested in come from the SNPFinder and CoverageSampler modules. To view the outputs, simply click on the view data icon (circled in red). Once the datasets have been selected, simply click the Run workflow button (circled in red). These outputs can then be downloaded to your local machine by clicking on the download icon (circled in red). For more information on interpreting the output from each of these tools, please see the CoverageSampler and SNPFinder output descriptions.","title":"View the Outputs"},{"location":"armplusplus/v1/running/upload/","text":"Upload Data into AMR++ Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Tutorial Data In the Use Tutorial Data section , we upload a sample data set using the Get Data module. This section is for those who are new to Galaxy and who want to get more comfortable with the Galaxy interface. Upload Your Data In the Upload My Own Data section, we use FileZilla to upload data via FTP. This section is for those who have large data sets (>2 GB) that they want to upload and run. Use Tutorial Data New to Galaxy? This section should get you up to speed with Galaxy and how to upload data. Step 1 Download Sample Data Let's get some sample data. Download the example data . The example data in this tutorial was taken from the full dataset of the human genome (hg38) , along with a paired metagenome sample (SRR532663) from the Human Microbiome Project (HMP) on NCBI. Once downloaded, unzip the sample_data.zip archive. You should see four files: SRR532663_1.fastq SRR532663_2.fastq production_resistance_database.fasta chr21.fasta Step 2 Upload Data There are a couple ways that we can upload these files to Galaxy: Via the Galaxy Get Data module Via a file transfer protocol (FTP) Note Currently, the Geta Data module only supports file uploads that are less than 2GB . If you wish to upload files larger than 2GB, you will need some FTP software such as FileZilla , however, it is not required for the sample data provided in this tutorial. Let's upload our data to Galaxy. First, make sure that your Galaxy server is running. Right now, you should be staring at a page similar to the following: Click on the Get Data link circled in red, and navigate to the underlined Upload File link. From here, we are given the options of Choosing a local file (highlighted in blue) or Choosing an FTP file (highlighted in orange). Let's choose a local file since our data is less than 2GB. If you want to upload via FTP, see the Upload My Own Data section. Navigate to the folder where you extracted the sample data, select the appropriate datasets, and upload them. Once selected, navigate to the Type column (circled in red) and specify the file type (highlighted in blue) for each dataset from the drop down menu. For each fastq dataset, select the fastqsanger option, and for each fasta dataset, select the fasta option. Next, click the Start button to begin uploading the data to your Galaxy server. If everything goes well, you should see all green. That's good! You can find the uploaded datasets in the right hand side of the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. - OR - Upload Your Own Data Using FTP to Manage Your Data In this section, we'll cover what you need to know to upload your own data via FTP. If you haven't already done so, head on over to FileZilla and download their FTP client. It's free and very easy to use. Step 1 Enter FTP Credentials Connecting to your FTP server is really easy. Navigate to the site manager (circled in red): Click on the New Site button (circled in red) and enter a name for your FTP connection. Next, click on the Transfer Settings button (circled in orange) and check the Active radio button under Transfer mode . Go back to the General tab and enter in your credentials; replacing the hostname with your own. Under User , enter in admin@galaxy.org and under Password enter admin . Step 2 Transfer Files Once connected, we can upload some files. On my machine, I have files on my Desktop under a directory called sample data (highlighted in blue). Navigate to the folder where your data is. You will see a list of files in that directory through the FTP client interface (highlighted in red). Simply drag and drop the desired files to the root directory as illustrated below. Step 3 Upload FTP Files Once the transfer has completed, navigate to the Get Data module on your Galaxy homepage and select the Upload File link. Next, click on the Choose FTP file option. Check all the boxes for each dataset. Next, find the Type tab in the next window and specify the file type for each file from the drop down menu. Choose fastq sanger for your fastq datasets and fasta for your fasta datasets. That's it! You should then see the files loading in your History pane on the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. Note You may need to refresh the history pane to see the uploaded datasets, which you can do by clicking on the Refresh history icon directly to the right of the history pane.","title":"Upload Data into AMR++"},{"location":"armplusplus/v1/running/upload/#upload-data-into-amr","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs.","title":"Upload Data into AMR++"},{"location":"armplusplus/v1/running/upload/#tutorial-data","text":"In the Use Tutorial Data section , we upload a sample data set using the Get Data module. This section is for those who are new to Galaxy and who want to get more comfortable with the Galaxy interface.","title":"Tutorial Data"},{"location":"armplusplus/v1/running/upload/#upload-your-data","text":"In the Upload My Own Data section, we use FileZilla to upload data via FTP. This section is for those who have large data sets (>2 GB) that they want to upload and run. Use Tutorial Data","title":"Upload Your Data"},{"location":"armplusplus/v1/running/upload/#new-to-galaxy","text":"This section should get you up to speed with Galaxy and how to upload data.","title":"New to Galaxy?"},{"location":"armplusplus/v1/running/upload/#step-1","text":"","title":"Step 1"},{"location":"armplusplus/v1/running/upload/#download-sample-data","text":"Let's get some sample data. Download the example data . The example data in this tutorial was taken from the full dataset of the human genome (hg38) , along with a paired metagenome sample (SRR532663) from the Human Microbiome Project (HMP) on NCBI. Once downloaded, unzip the sample_data.zip archive. You should see four files: SRR532663_1.fastq SRR532663_2.fastq production_resistance_database.fasta chr21.fasta","title":"Download Sample Data"},{"location":"armplusplus/v1/running/upload/#step-2","text":"","title":"Step 2"},{"location":"armplusplus/v1/running/upload/#upload-data","text":"There are a couple ways that we can upload these files to Galaxy: Via the Galaxy Get Data module Via a file transfer protocol (FTP) Note Currently, the Geta Data module only supports file uploads that are less than 2GB . If you wish to upload files larger than 2GB, you will need some FTP software such as FileZilla , however, it is not required for the sample data provided in this tutorial. Let's upload our data to Galaxy. First, make sure that your Galaxy server is running. Right now, you should be staring at a page similar to the following: Click on the Get Data link circled in red, and navigate to the underlined Upload File link. From here, we are given the options of Choosing a local file (highlighted in blue) or Choosing an FTP file (highlighted in orange). Let's choose a local file since our data is less than 2GB. If you want to upload via FTP, see the Upload My Own Data section. Navigate to the folder where you extracted the sample data, select the appropriate datasets, and upload them. Once selected, navigate to the Type column (circled in red) and specify the file type (highlighted in blue) for each dataset from the drop down menu. For each fastq dataset, select the fastqsanger option, and for each fasta dataset, select the fasta option. Next, click the Start button to begin uploading the data to your Galaxy server. If everything goes well, you should see all green. That's good! You can find the uploaded datasets in the right hand side of the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. - OR - Upload Your Own Data","title":"Upload Data"},{"location":"armplusplus/v1/running/upload/#using-ftp-to-manage-your-data","text":"In this section, we'll cover what you need to know to upload your own data via FTP. If you haven't already done so, head on over to FileZilla and download their FTP client. It's free and very easy to use.","title":"Using FTP to Manage Your Data"},{"location":"armplusplus/v1/running/upload/#step-1_1","text":"","title":"Step 1"},{"location":"armplusplus/v1/running/upload/#enter-ftp-credentials","text":"Connecting to your FTP server is really easy. Navigate to the site manager (circled in red): Click on the New Site button (circled in red) and enter a name for your FTP connection. Next, click on the Transfer Settings button (circled in orange) and check the Active radio button under Transfer mode . Go back to the General tab and enter in your credentials; replacing the hostname with your own. Under User , enter in admin@galaxy.org and under Password enter admin .","title":"Enter FTP Credentials"},{"location":"armplusplus/v1/running/upload/#step-2_1","text":"","title":"Step 2"},{"location":"armplusplus/v1/running/upload/#transfer-files","text":"Once connected, we can upload some files. On my machine, I have files on my Desktop under a directory called sample data (highlighted in blue). Navigate to the folder where your data is. You will see a list of files in that directory through the FTP client interface (highlighted in red). Simply drag and drop the desired files to the root directory as illustrated below.","title":"Transfer Files"},{"location":"armplusplus/v1/running/upload/#step-3","text":"","title":"Step 3"},{"location":"armplusplus/v1/running/upload/#upload-ftp-files","text":"Once the transfer has completed, navigate to the Get Data module on your Galaxy homepage and select the Upload File link. Next, click on the Choose FTP file option. Check all the boxes for each dataset. Next, find the Type tab in the next window and specify the file type for each file from the drop down menu. Choose fastq sanger for your fastq datasets and fasta for your fasta datasets. That's it! You should then see the files loading in your History pane on the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. Note You may need to refresh the history pane to see the uploaded datasets, which you can do by clicking on the Refresh history icon directly to the right of the history pane.","title":"Upload FTP Files"},{"location":"armplusplus/v1/setup/import/","text":"Import Workflow Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Before we can run some data, we need to import the AmrPlusPlus workflow. Follow the instructions below. Workflow Installation Step 1 Step 1 Navigate to the Workflow tab at the top of the Galaxy homepage. Step 2 Step 2 Click on the Upload or import workflow tab at the top right of the page. Step 3 Step 3 Click on the Visit myExperiment link at the bottom of the page. Step 4 Step 4 Type in amrplusplus into the search box. Step 5 Step 5 You will see two workflows (amrplusplus single-end workflow and amrplusplus paired-end workflow). Click on the amrplusplus paired-end workflow link. You can download the single-end workflow, but we'll be using the paired workflow when we get to the Run Workflow section. Then, click on the Import button in the middle of the page. Step 6 Step 6 Now, let's upload some data .","title":"Import AMR++ Workflow"},{"location":"armplusplus/v1/setup/import/#import-workflow","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. Before we can run some data, we need to import the AmrPlusPlus workflow. Follow the instructions below.","title":"Import Workflow"},{"location":"armplusplus/v1/setup/import/#workflow-installation","text":"Step 1","title":"Workflow Installation"},{"location":"armplusplus/v1/setup/import/#step-1","text":"Navigate to the Workflow tab at the top of the Galaxy homepage. Step 2","title":"Step 1"},{"location":"armplusplus/v1/setup/import/#step-2","text":"Click on the Upload or import workflow tab at the top right of the page. Step 3","title":"Step 2"},{"location":"armplusplus/v1/setup/import/#step-3","text":"Click on the Visit myExperiment link at the bottom of the page. Step 4","title":"Step 3"},{"location":"armplusplus/v1/setup/import/#step-4","text":"Type in amrplusplus into the search box. Step 5","title":"Step 4"},{"location":"armplusplus/v1/setup/import/#step-5","text":"You will see two workflows (amrplusplus single-end workflow and amrplusplus paired-end workflow). Click on the amrplusplus paired-end workflow link. You can download the single-end workflow, but we'll be using the paired workflow when we get to the Run Workflow section. Then, click on the Import button in the middle of the page. Step 6","title":"Step 5"},{"location":"armplusplus/v1/setup/import/#step-6","text":"Now, let's upload some data .","title":"Step 6"},{"location":"armplusplus/v1/setup/installation/","text":"Installation Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. The following installation will take approximately 30 minutes. Software Requirements To install Docker, you will need access to one of the following operating systems: Mac OS X (10.8 or above) Linux 64-bit Docker Install via Docker Why Install via Docker? Docker packages an entire piece of software into its own filesystem. Docker rids users of dependency nightmares caused by complex software. Step 1 Download Docker Mac Users: Follow the instructions here . Linux Users: Follow the instructions here . Note You must have sudo privileges to install Docker via Linux. Step 2 Start Docker with a Mac Open your Launchpad, and click on the DockerQuickStart icon. This will open a terminal and start Docker using a default virtual machine. Be sure to take note of the IP address (highlighted in red) Docker was started on. The IP address will be different than the one highlighted below. To launch your Galaxy instance, type this exact command into the terminal (omitting the '$' sign): $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Start Docker with Linux Open a terminal, and type these exact commands (omitting the '$' sign): $ sudo service docker start $ sudo docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Note When running these commands for the first time, Docker will go out and look for the chrisd/amrplusplus repository and download the latest AmrPlusPlus Docker image. When the install completes, you should see a message similar to the one below. $ Digest: sha256:7e992b68ddb9a2e37a9f2b862de015445912d20cc98d13970603939330b0433e $ Status: Downloaded newer image for chrisd/amrplusplus:latest $ 10ab4d35cf798a2e46a0ec4e2eaf15377c3558772b3f5d0e1107025a9b922f76 If you see this message, that means the latest version of the pipeline was downloaded successfully and is currently running on your machine. Step 3 Connecting to the Server on a Mac Open a web browser, and navigate to: http://default-ip:8080 Warning Replace deafult-ip with the IP address Docker was started on. For example, if the IP address was 192.000.00.000, then you would enter http://192.000.00.000:8080 into your web browser. If you forgot the IP address, you can find it by scrolling to the top of your terminal. Connecting to the Server on Linux Open a web browser, and navigate to: localhost:8080 Once connected, you should see a page similar to the following: Step 4 Log in to Server Next, we need to login. From the navigation bar at the top of the Galaxy homepage, click on the User tab and goto Login . In the Username field, enter admin@galaxy.org and in the Password field, enter admin and click on the Login button. Step 5 Import Workflow Next, we need to Import the Workflow . Galaxy Install via Galaxy Before You Begin If you installed Galaxy via Docker, you do not need to read this section. Galaxy comes installed when you run Docker. See the Import Workflow for next steps. This section is only for those who have a production Galaxy server and wish to download the AmrPlusPlus pipeline via the Galaxy Main Toolshed. Software Requirements Production Galaxy Server Admin account GNU Make and GCC compiler Tool Installation Log in to your Galaxy server with your admin account. Find the admin tab in the navigation bar -> Search Tool Shed -> Galaxy Main Toolshed ->Browse Valid Repositories -> Metagenomics -> suite_amrplusplus -> Preview and Install. Click on the Install button at the top of the page. Make sure the Handle Repository Dependencies and Handle Tool Dependencies boxes are checked. In the Add New Tool Section Panel, enter AmrPlusPlus into the text box. Click on the Install button at the bottom of the page.","title":"Installation to Run AMR++"},{"location":"armplusplus/v1/setup/installation/#installation","text":"Warning This documentation is for AMR++ version 1.1. Click here for the latest docs. The following installation will take approximately 30 minutes.","title":"Installation"},{"location":"armplusplus/v1/setup/installation/#software-requirements","text":"To install Docker, you will need access to one of the following operating systems: Mac OS X (10.8 or above) Linux 64-bit","title":"Software Requirements"},{"location":"armplusplus/v1/setup/installation/#docker","text":"Install via Docker Why Install via Docker? Docker packages an entire piece of software into its own filesystem. Docker rids users of dependency nightmares caused by complex software.","title":"Docker"},{"location":"armplusplus/v1/setup/installation/#step-1","text":"","title":"Step 1"},{"location":"armplusplus/v1/setup/installation/#download-docker","text":"Mac Users: Follow the instructions here . Linux Users: Follow the instructions here . Note You must have sudo privileges to install Docker via Linux.","title":"Download Docker"},{"location":"armplusplus/v1/setup/installation/#step-2","text":"","title":"Step 2"},{"location":"armplusplus/v1/setup/installation/#start-docker-with-a-mac","text":"Open your Launchpad, and click on the DockerQuickStart icon. This will open a terminal and start Docker using a default virtual machine. Be sure to take note of the IP address (highlighted in red) Docker was started on. The IP address will be different than the one highlighted below. To launch your Galaxy instance, type this exact command into the terminal (omitting the '$' sign): $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus","title":"Start Docker with a Mac"},{"location":"armplusplus/v1/setup/installation/#start-docker-with-linux","text":"Open a terminal, and type these exact commands (omitting the '$' sign): $ sudo service docker start $ sudo docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Note When running these commands for the first time, Docker will go out and look for the chrisd/amrplusplus repository and download the latest AmrPlusPlus Docker image. When the install completes, you should see a message similar to the one below. $ Digest: sha256:7e992b68ddb9a2e37a9f2b862de015445912d20cc98d13970603939330b0433e $ Status: Downloaded newer image for chrisd/amrplusplus:latest $ 10ab4d35cf798a2e46a0ec4e2eaf15377c3558772b3f5d0e1107025a9b922f76 If you see this message, that means the latest version of the pipeline was downloaded successfully and is currently running on your machine.","title":"Start Docker with Linux"},{"location":"armplusplus/v1/setup/installation/#step-3","text":"","title":"Step 3"},{"location":"armplusplus/v1/setup/installation/#connecting-to-the-server-on-a-mac","text":"Open a web browser, and navigate to: http://default-ip:8080 Warning Replace deafult-ip with the IP address Docker was started on. For example, if the IP address was 192.000.00.000, then you would enter http://192.000.00.000:8080 into your web browser. If you forgot the IP address, you can find it by scrolling to the top of your terminal.","title":"Connecting to the Server on a Mac"},{"location":"armplusplus/v1/setup/installation/#connecting-to-the-server-on-linux","text":"Open a web browser, and navigate to: localhost:8080 Once connected, you should see a page similar to the following:","title":"Connecting to the Server on Linux"},{"location":"armplusplus/v1/setup/installation/#step-4","text":"","title":"Step 4"},{"location":"armplusplus/v1/setup/installation/#log-in-to-server","text":"Next, we need to login. From the navigation bar at the top of the Galaxy homepage, click on the User tab and goto Login . In the Username field, enter admin@galaxy.org and in the Password field, enter admin and click on the Login button.","title":"Log in to Server"},{"location":"armplusplus/v1/setup/installation/#step-5","text":"","title":"Step 5"},{"location":"armplusplus/v1/setup/installation/#import-workflow","text":"Next, we need to Import the Workflow .","title":"Import Workflow"},{"location":"armplusplus/v1/setup/installation/#galaxy","text":"Install via Galaxy","title":"Galaxy"},{"location":"armplusplus/v1/setup/installation/#before-you-begin","text":"If you installed Galaxy via Docker, you do not need to read this section. Galaxy comes installed when you run Docker. See the Import Workflow for next steps. This section is only for those who have a production Galaxy server and wish to download the AmrPlusPlus pipeline via the Galaxy Main Toolshed.","title":"Before You Begin"},{"location":"armplusplus/v1/setup/installation/#software-requirements_1","text":"Production Galaxy Server Admin account GNU Make and GCC compiler","title":"Software Requirements"},{"location":"armplusplus/v1/setup/installation/#tool-installation","text":"Log in to your Galaxy server with your admin account. Find the admin tab in the navigation bar -> Search Tool Shed -> Galaxy Main Toolshed ->Browse Valid Repositories -> Metagenomics -> suite_amrplusplus -> Preview and Install. Click on the Install button at the top of the page. Make sure the Handle Repository Dependencies and Handle Tool Dependencies boxes are checked. In the Add New Tool Section Panel, enter AmrPlusPlus into the text box. Click on the Install button at the bottom of the page.","title":"Tool Installation"}]}